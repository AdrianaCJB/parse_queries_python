{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levantamiento Acciones Comerciales - Querys de CIM desde Teradata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **PROYECTO : LEVANTAMIENTO CÓDIGO CIM EN EL GESTOR DE CAMPANAS TERADATA** <br> \n",
    "**Extracción de tablas, campos y reglas utilizadas directamente desde CIM según una lista de comunicaciones específica** <br>\n",
    "El archivo __query_segmentos_CIM_prod.txt__ tiene la query que extrae las comunicaciones, segmentaciones y su ultima query ejecutada <br>\n",
    "Versión:  1.0  <br>\n",
    "Fecha: 01-05-2020  <br>\n",
    "Descripción: Versión Inicial  <br>\n",
    "Desarrollador: Axity | Adriana Jiménez "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os, glob\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from decimal import Decimal as D\n",
    "import datetime\n",
    "\n",
    "## Librerias de parseo de queries\n",
    "import sqlparse\n",
    "from sqlparse.sql import TokenList\n",
    "from sqlparse.tokens import Name, Whitespace, Wildcard, Number, Punctuation, Text, Operator, Literal\n",
    "from sqlparse.tokens import DML, DDL, Keyword\n",
    "import sql_metadata as sqllib\n",
    "\n",
    "\n",
    "## Libreria que se integra con Teradata\n",
    "import giraffez\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones: Insertar en BD Teradata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuracion de conexion\n",
    "td_config = {\n",
    "    \"username\": \"exajibl\",\n",
    "    \"password\": \"acjb0610\",\n",
    "    \"host\": \"dataware.bci.cl\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_drop_tables_teradata():\n",
    "    '''\n",
    "    Función que crea las tablas en Teradata\n",
    "    '''\n",
    "    \n",
    "    print(\"ELIMINANDO Y CREANDO TABLAS..\\n\")\n",
    "    \n",
    "    drop_sql_cim   = \"DROP TABLE EDW_TEMPUSU.LAC_LEVANTAMIENTO_CIM\"\n",
    "\n",
    "    create_sql_cim = \"\"\"CREATE MULTISET TABLE EDW_TEMPUSU.LAC_LEVANTAMIENTO_CIM\n",
    "        (\n",
    "          NOMBRE_COMUNICACION VARCHAR(100) ,\n",
    "          NOMBRE_SEGMENTO VARCHAR(100),\n",
    "          MULTINIVEL VARCHAR(30),\n",
    "          ESQUEMA_INPUT VARCHAR(100) ,\n",
    "          TABLA_INPUT VARCHAR(100),\n",
    "          ALIAS_SUBQUERY VARCHAR(50) ,\n",
    "          COLUMNA VARCHAR(60) ,\n",
    "          VARIABLE VARCHAR(100) ,\n",
    "          LOGICA_NEGOCIO VARCHAR(28000),\n",
    "          ALIAS_CAMPO VARCHAR(50)     \n",
    "          ) ;\"\"\"\n",
    "\n",
    "\n",
    "    with giraffez.Cmd(**td_config) as cmd:\n",
    "        if cmd.exists(\"EDW_TEMPUSU.LAC_LEVANTAMIENTO_CIM\"):\n",
    "            cmd.execute(drop_sql_cim)\n",
    "\n",
    "        cmd.execute(create_sql_cim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_files_csv_in_teradata():\n",
    "    \n",
    "    df_cim = pd.read_csv(\"LAC_Levantamiento_CIM.csv\",  sep='|' )  \n",
    "\n",
    "    if (df_cim.empty == False): \n",
    "    \n",
    "        print(\"INSERTANDO ARCHIVO A LA TABLA EDW_TEMPUSU.LAC_LEVANTAMIENTO_CIM..\\n\")\n",
    "        \n",
    "        df_cim['NOMBRE_COMUNICACION'] = df_cim['NOMBRE_COMUNICACION'].astype('str')\n",
    "        df_cim['NOMBRE_SEGMENTO']     = df_cim['NOMBRE_SEGMENTO'].astype('str')\n",
    "        df_cim['MULTINIVEL']          = df_cim['MULTINIVEL'].astype('str')\n",
    "        df_cim['ESQUEMA_INPUT']       = df_cim['ESQUEMA_INPUT'].astype('str')\n",
    "        df_cim['TABLA_INPUT']         = df_cim['TABLA_INPUT'].astype('str')\n",
    "        df_cim['ALIAS_SUBQUERY']      = df_cim['ALIAS_SUBQUERY'].astype('str')\n",
    "        df_cim['COLUMNA']             = df_cim['COLUMNA'].astype('str')\n",
    "        df_cim['VARIABLE']            = df_cim['VARIABLE'].astype('str')\n",
    "        df_cim['LOGICA_NEGOCIO']      = df_cim['LOGICA_NEGOCIO'].astype('str')\n",
    "        df_cim['ALIAS_CAMPO']         = df_cim['ALIAS_CAMPO'].astype('str')\n",
    "        \n",
    "        with giraffez.BulkLoad(\"EDW_TEMPUSU.LAC_LEVANTAMIENTO_CIM\", **td_config) as load:\n",
    "            load.cleanup()\n",
    "            load.columns = df_cim.columns.tolist()\n",
    "            for row in df_cim.values.tolist(): \n",
    "                load.put([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9] ])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones modificadas de librería sql_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(_list):\n",
    "    \"\"\"\n",
    "    Hace que una lista tenga registro unicos y mantengan el orden\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "\n",
    "    for item in _list:\n",
    "        if item not in ret:\n",
    "            ret.append(item)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDataframeTablesColumnsQuery(df_final_tables, df_final_columns):\n",
    "    '''\n",
    "    Función que une las tablas con los campos según el multinivel al que corresponde\n",
    "    ''' \n",
    "    \n",
    "    columnsDF = ['MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT','ALIAS_SUBQUERY',\n",
    "                 'NOMBRE_CAMPO', 'CAMPO_COMPUESTO','LOGICA_NEGOCIO','ALIAS_CAMPO']\n",
    "    \n",
    "    \n",
    "    # Divide la columna \"CAMPOS\" haciendo split '.'\n",
    "    # Obtengo un ALIAS temporal del CAMPO\n",
    "    df_tmp_columns = df_final_columns.CAMPOS.str.split(\".\", n=3, expand=True)\n",
    "    \n",
    "    \n",
    "    if (df_tmp_columns.empty == False):\n",
    "        # Para los casos que viene el campo en formato: esquema.tabla.campo\n",
    "        if (len(df_tmp_columns.columns) == 3): \n",
    "            df_final_columns['ALIAS_TMP']  = 'N/A'\n",
    "            df_final_columns[['COLUMNA_1','COLUMNA_2','NOMBRE_CAMPO']] = \\\n",
    "                                df_final_columns.CAMPOS.str.split(\".\", n=3, expand=True)\n",
    "\n",
    "            for index, row in df_final_columns.iterrows(): \n",
    "                if ((row[\"NOMBRE_CAMPO\"] == None or row[\"NOMBRE_CAMPO\"] == np.NaN) \\\n",
    "                and (row[\"COLUMNA_2\"]    == None or row[\"COLUMNA_2\"]    == np.NaN) ):\n",
    "                    row[\"NOMBRE_CAMPO\"] = row[\"COLUMNA_1\"]                 \n",
    "\n",
    "                elif (row[\"NOMBRE_CAMPO\"] == None or row[\"NOMBRE_CAMPO\"] == np.NaN ):\n",
    "                    row[\"NOMBRE_CAMPO\"] = row[\"COLUMNA_2\"] \n",
    "                    row[\"ALIAS_TMP\"]    = row[\"COLUMNA_1\"] \n",
    "\n",
    "\n",
    "        # Para los casos que viene el campo en formato: alias.campo    \n",
    "        if (len(df_tmp_columns.columns) == 2):    \n",
    "            df_final_columns[['ALIAS_TMP','NOMBRE_CAMPO']] = df_final_columns.CAMPOS.str.split(\".\", n=2, expand=True)\n",
    "\n",
    "            for index, row in df_final_columns.iterrows(): \n",
    "                if (row[\"NOMBRE_CAMPO\"] == None or row[\"NOMBRE_CAMPO\"] == np.NaN ):\n",
    "                    row[\"NOMBRE_CAMPO\"] = row[\"ALIAS_TMP\"] \n",
    "                    row[\"ALIAS_TMP\"]    = 'N/A'\n",
    "\n",
    "\n",
    "        # Para los casos que viene el campo en formato: campo   \n",
    "        elif (len(df_tmp_columns.columns) == 1): \n",
    "            df_final_columns['ALIAS_TMP']  = 'N/A'\n",
    "            df_final_columns['NOMBRE_CAMPO'] = df_final_columns.CAMPOS.str.split(\".\", n=1, expand=True)\n",
    "\n",
    "\n",
    "            \n",
    "        df_final_columns['ALIAS_TMP']  = df_final_columns['ALIAS_TMP'].str.upper() \n",
    "        df_final_tables['ALIAS_TABLA'] = df_final_tables['ALIAS_TABLA'].str.upper() \n",
    "\n",
    "        # Merge para los match completos entre campos y tablas (INNER JOIN)  \n",
    "        df_merge = pd.merge(df_final_columns, df_final_tables, \\\n",
    "                            left_on  =[\"MULTINIVEL\",\"ALIAS_TMP\"], right_on =[\"MULTINIVEL\",\"ALIAS_TABLA\"], \\\n",
    "                            how ='left')\n",
    "\n",
    "\n",
    "        # Los casos en que las subquery tiene una sola tabla y los campos no tienen esquema, asignar esa tabla\n",
    "        # Cuento la cantidad de tablas que tiene un multinivel\n",
    "        df_count_tables = df_final_tables.groupby(['MULTINIVEL'])['ESQUEMA_INPUT','TABLA_INPUT'].count()\n",
    "\n",
    "        # Obtengo los multiniveles que solo tienen 1 tabla \n",
    "        df_count_tables = df_count_tables[(df_count_tables['ESQUEMA_INPUT'] == 1) \\\n",
    "                                        & (df_count_tables['TABLA_INPUT'] == 1)].reset_index()\n",
    "        df_count_tables = df_count_tables[['MULTINIVEL']]\n",
    "\n",
    "        # Hago merge con el dataframe anterior para obtener de nuevo los nombres\n",
    "        df_merge_count = pd.merge(df_final_tables, df_count_tables, on  =[\"MULTINIVEL\"], how ='inner')\n",
    "\n",
    "\n",
    "        # Asigna a los campos que no tienen match, su tabla correspondiente, en los casos de 1 sola tabla\n",
    "        for index, row in df_merge_count.iterrows(): \n",
    "            df_merge['ESQUEMA_INPUT'] = np.where((df_merge['MULTINIVEL'] == row['MULTINIVEL']) & \\\n",
    "                                                (df_merge['ALIAS_TMP'] == 'N/A'), \\\n",
    "                                                row[\"ESQUEMA_INPUT\"], df_merge[\"ESQUEMA_INPUT\"] )        \n",
    "\n",
    "            df_merge['TABLA_INPUT'] = np.where((df_merge['MULTINIVEL'] == row['MULTINIVEL']) & \\\n",
    "                                              (df_merge['ALIAS_TMP'] == 'N/A'), \\\n",
    "                                              row[\"TABLA_INPUT\"], df_merge[\"TABLA_INPUT\"] )\n",
    "\n",
    "            df_merge['ALIAS_TABLA'] = np.where((df_merge['MULTINIVEL'] == row['MULTINIVEL']) & \\\n",
    "                                           (df_merge['ALIAS_TMP'] == 'N/A'), \\\n",
    "                                           row[\"ALIAS_TABLA\"], df_merge[\"ALIAS_TABLA\"] )\n",
    "\n",
    "            df_merge['ALIAS_SUBQUERY'] = np.where((df_merge['MULTINIVEL'] == row['MULTINIVEL']) & \\\n",
    "                                           (df_merge['ALIAS_TMP'] == 'N/A'), \\\n",
    "                                           row[\"ALIAS_SUBQUERY\"], df_merge[\"ALIAS_SUBQUERY\"] )\n",
    "\n",
    "\n",
    "        # Genero un campo compuesto con el formato esquema.tabla.campo \n",
    "        cols = ['ESQUEMA_INPUT', 'TABLA_INPUT', 'NOMBRE_CAMPO']\n",
    "        df_merge['CAMPO_COMPUESTO'] = df_merge[cols].apply(lambda row: '.'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "        # Obtego las columnas que quiero del df \n",
    "        df_merge_final = df_merge[columnsDF] \n",
    "\n",
    "    \n",
    "    return df_merge_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertDataframeTablesQuery(df_total_tables, multilevel, table_list, subquery_alias):\n",
    "    '''\n",
    "    Función que inserta en un dataframe los objetos de una query\n",
    "    '''\n",
    "\n",
    "    new_df_tables       = emptyDataframeTablesQuery(None)\n",
    "    \n",
    "    #print (\" ****** LISTA TABLAS  -> \"          + str(table_list)) \n",
    "    \n",
    "    \n",
    "    ## SECCION DE INSERCION DE TABLAS SOLAMENTE\n",
    "    for item in table_list:\n",
    "        tamañoItem = len(item)\n",
    "        \n",
    "        if (tamañoItem == 3):\n",
    "            new_df_tables = new_df_tables.append(\n",
    "                [ {'MULTINIVEL': multilevel ,\n",
    "                   'ESQUEMA_INPUT': item[0],\n",
    "                   'TABLA_INPUT': item[1], \n",
    "                   'ALIAS_TABLA' : item[2] }], \n",
    "                    ignore_index=True, sort=False) \n",
    "                           \n",
    "        elif (tamañoItem == 2):\n",
    "            new_df_tables = new_df_tables.append(\n",
    "                [ {'MULTINIVEL': multilevel ,\n",
    "                   'ESQUEMA_INPUT': item[0],\n",
    "                   'TABLA_INPUT': item[1] }], \n",
    "                    ignore_index=True, sort=False) \n",
    "        \n",
    "    \n",
    "    new_df_tables = new_df_tables.assign( ALIAS_SUBQUERY = subquery_alias )   \n",
    "    df_total_tables = df_total_tables.append(new_df_tables)\n",
    "    \n",
    "    \n",
    "    return df_total_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertDataframeColumnsQuery(df_total_columns, multilevel, column_list, column_list_total,\n",
    "            rule_select_list_total, rule_generic_list_total):\n",
    "    '''\n",
    "    Función que inserta en un dataframe los objetos de una query\n",
    "    '''\n",
    "    \n",
    "    new_df_column       = emptyDataframeColumnsQuery(None)\n",
    "    new_df_internal     = emptyDataframeColumnsQuery(None)\n",
    "    \n",
    "    # Lista los campos que tuvieron logica asociada\n",
    "    check_rule_columns  = []\n",
    "    \n",
    "    # Lista temporal de campos y reglas\n",
    "    list_columns_rules  = []\n",
    "    alias               = ''\n",
    "    flag_column_with_as = False  # Se activa si consigue que un campo contiene alias\n",
    "    column_list = unique(column_list) \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print (\" ****** POSICION DE MULTINIVEL -> \" + str(multilevel))\n",
    "    print (\" ****** LISTA CAMPOS  -> \"          + str(column_list))\n",
    "    print (\" ****** LISTA CAMPOS TOTAL  -> \"    + str(column_list_total))\n",
    "    print (\" ****** LISTA LOGICAS SELECT -> \"   + str(rule_select_list_total)) \n",
    "    print (\" ****** LISTA LOGICAS FILTROS -> \"  + str(rule_generic_list_total)) \n",
    "    '''\n",
    "    \n",
    "    ## Recorre la lista de las reglas y si existe un campo que esté contenido en la regla\n",
    "    ## entonces inserta en la misma fila el campo y la regla interna.      \n",
    "    if (rule_select_list_total):\n",
    "        \n",
    "        ## Logicas de los 'select'\n",
    "        for rule in rule_select_list_total:\n",
    "            flag_column_rule = False\n",
    "            \n",
    "            # Recorre cada campo para hacer match con la regla/logica\n",
    "            for column in column_list:                 \n",
    "                if (column in rule[0] and column != rule[1]):                  \n",
    "                    flag_column_rule = True\n",
    "                    new_df_column = new_df_column.append(\n",
    "                    [{  'MULTINIVEL': multilevel , \n",
    "                        'CAMPOS': column,\n",
    "                        'LOGICA_NEGOCIO' : rule[0],\n",
    "                        'ALIAS_CAMPO'   : rule[1]\n",
    "                    }], \n",
    "                     ignore_index=True, sort=False)                 \n",
    "                    check_rule_columns.append(column)\n",
    "                    new_df_internal = new_df_internal.append(new_df_column,ignore_index=True, sort=False)\n",
    "                    \n",
    "                    \n",
    "            ## Si la regla no tiene campo, insertarla de igual forma        \n",
    "            if (flag_column_rule == False):\n",
    "                new_df_column = new_df_column.append(\n",
    "                [{  'MULTINIVEL': multilevel ,\n",
    "                    'CAMPOS': None,\n",
    "                    'LOGICA_NEGOCIO' : rule[0],\n",
    "                    'ALIAS_CAMPO'   : rule[1]\n",
    "                }], \n",
    "                 ignore_index=True, sort=False) \n",
    "                new_df_internal = new_df_internal.append(new_df_column,ignore_index=True, sort=False)\n",
    "         \n",
    "    ## Logicas de negocio de los filtros\n",
    "    if (rule_generic_list_total):\n",
    "        for rule in rule_generic_list_total:\n",
    "            for column in column_list: \n",
    "                if (column in rule):\n",
    "                    new_df_column = new_df_column.append(\n",
    "                    [{  'MULTINIVEL': multilevel ,\n",
    "                        'CAMPOS': column,\n",
    "                        'LOGICA_NEGOCIO' : rule}], \n",
    "                     ignore_index=True, sort=False) \n",
    "                    \n",
    "                    check_rule_columns.append(column)\n",
    "                    new_df_internal = new_df_internal.append(new_df_column,ignore_index=True, sort=False)\n",
    "            \n",
    "    \n",
    "    ## los campos solos que no tengan regla asociada, se insertan al final\n",
    "    ## pero hay que validar si tienen alias también\n",
    "    columns_without_rules = list(set(column_list) - set(check_rule_columns))        \n",
    "    \n",
    "    \n",
    "    if (columns_without_rules):\n",
    "        for column_w_r in columns_without_rules:  \n",
    "            flag_column_with_as = False\n",
    "            \n",
    "            if (column_list_total):\n",
    "                for column_as in column_list_total:\n",
    "                    \n",
    "                    field = column_as[0]\n",
    "                    len_list_field = len(column_as)\n",
    "                    \n",
    "                    if (len_list_field == 2):\n",
    "                        if (field != None and column_w_r == field):\n",
    "                            flag_column_with_as = True\n",
    "                            alias = column_as[1]                            \n",
    "                            new_df_column = new_df_column.append(\n",
    "                                        [{  'MULTINIVEL': multilevel ,\n",
    "                                            'CAMPOS': field,\n",
    "                                            'ALIAS_CAMPO': alias \n",
    "                                         }], \n",
    "                                         ignore_index=True, sort=False)  \n",
    "                            \n",
    "            ## Si el campo de la lista de campos sin reglas no tiene alias, insertar al final\n",
    "            if (flag_column_with_as == False):           \n",
    "                new_df_column = new_df_column.append(\n",
    "                            [{  'MULTINIVEL': multilevel ,\n",
    "                                'CAMPOS': column_w_r,\n",
    "                                'ALIAS_CAMPO': None \n",
    "                             }], \n",
    "                             ignore_index=True, sort=False) \n",
    "            \n",
    "            new_df_internal = new_df_internal.append(new_df_column,ignore_index=True, sort=False)\n",
    "    \n",
    "            \n",
    "    if (new_df_internal.empty == False):        \n",
    "        new_df_internal  = new_df_internal.drop_duplicates()    \n",
    "        new_df_internal  = new_df_internal.sort_values(by ='CAMPOS')\n",
    "        df_total_columns = df_total_columns.append(new_df_internal,ignore_index=True, sort=False)\n",
    "        \n",
    "    \n",
    "    return df_total_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateInDataFrameColumnsRules(df_tables_columns, rule_generic_list_total):\n",
    "    '''Función que actualiza o inserta en los campos las ultimas reglas encontradas en la query.\n",
    "    Es decir, multiquery = 1 y antes del final con ; \n",
    "    '''   \n",
    "    last_rules    = []\n",
    "    internal_rule = []\n",
    "        \n",
    "    if (rule_generic_list_total and df_tables_columns.empty == False):\n",
    "        for rule in rule_generic_list_total: \n",
    "            \n",
    "            # Si el campo No tiene lógica de negocio o regla, se actualiza el df\n",
    "            df_tables_columns['LOGICA_NEGOCIO'] = \\\n",
    "                df_tables_columns.apply(lambda df: rule \\\n",
    "                   if (str(df['CAMPOS']) in rule and df['LOGICA_NEGOCIO'] is np.nan) \\\n",
    "                    else df['LOGICA_NEGOCIO'], axis=1)\n",
    "\n",
    "\n",
    "            # Si el campo Si tiene lógica de negocio o regla diferente a la insertada,\n",
    "            # se inserta el nuevo al df            \n",
    "            for index, row in df_tables_columns.iterrows(): \n",
    "                if (row[\"MULTINIVEL\"] == '1' and \\\n",
    "                    str(row[\"CAMPOS\"]) in rule and \\\n",
    "                    row[\"LOGICA_NEGOCIO\"] != rule ):\n",
    "\n",
    "                    internal_rule = [row[\"MULTINIVEL\"], row[\"CAMPOS\"], rule]\n",
    "                    last_rules.append(internal_rule)\n",
    "            \n",
    "    last_rules = unique(last_rules)    \n",
    "    new_dataframe = pd.DataFrame(last_rules, columns = ['MULTINIVEL','CAMPOS','LOGICA_NEGOCIO'] )\n",
    "    \n",
    "    df_tables_columns = df_tables_columns.append(new_dataframe, ignore_index=True)\n",
    "    \n",
    "    return df_tables_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_number_by_list(list_unique_str_num_query, last_number_subquery):\n",
    "    ''' Función que crea el multinivel de las queries, \n",
    "        con secuencia: 1.1, 1.2, 1.2.1, según lista de multiveles ya creados\n",
    "    '''    \n",
    "    list_final = []\n",
    "    \n",
    "    lenght_list       = len(list_unique_str_num_query)\n",
    "    length_last_query = len(last_number_subquery)\n",
    "    \n",
    "    if (length_last_query == 1 and lenght_list > 1):        \n",
    "        for item in list_unique_str_num_query:\n",
    "            \n",
    "            if (len(item) == 3):\n",
    "                first_item = item.split('.')[0]\n",
    "                \n",
    "                if (first_item == last_number_subquery):\n",
    "                    list_final.append(item)\n",
    "                \n",
    "        if list_final:\n",
    "            last_multilevel      = max(list_final)\n",
    "            split                = last_multilevel[:-1]\n",
    "            last_number          = last_multilevel[-1]\n",
    "            next_number          = int(last_number) + 1\n",
    "            new_number_subquery  = split + str(next_number)\n",
    "        else:\n",
    "            new_number_subquery  = last_number_subquery + '.1'\n",
    "        \n",
    "    elif (length_last_query >= 3 and lenght_list > 1):      \n",
    "        for item in list_unique_str_num_query:\n",
    "            if (len(item) == length_last_query + 2 and \\\n",
    "               last_number_subquery in item):\n",
    "                list_final.append(item)\n",
    "        \n",
    "        if list_final:\n",
    "            last_multilevel      = max(list_final)\n",
    "            split                = last_multilevel[:-1]\n",
    "            last_number          = last_multilevel[-1]\n",
    "            next_number          = int(last_number) + 1\n",
    "            new_number_subquery  = split + str(next_number)\n",
    "        else:\n",
    "            new_number_subquery  = last_number_subquery + '.1'\n",
    "   \n",
    "    else:\n",
    "        new_number_subquery  = '1.1'   \n",
    "        \n",
    "        \n",
    "    return new_number_subquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNumberedListSubquery(flag_get_in_subquery, flag_lastjoin_is_subquery,\n",
    "                                 flag_union_join_query, count_query_multilevel, \n",
    "                                 last_number_subquery, list_unique_str_num_query):\n",
    "    ''' \n",
    "    Función que crea el multinivel de las queries, con secuencia: 1.1, 1.2, 1.2.1, etc\n",
    "    '''\n",
    "    \n",
    "    point = '.'\n",
    "    new_number_subquery = None\n",
    "    entered_in_other_rule = False\n",
    "    length_last_query = len(last_number_subquery)\n",
    "    \n",
    "    '''\n",
    "    print(\"last_number_subquery      ---> \"+ last_number_subquery + \", length_last_query ---> \"+ str(length_last_query))\n",
    "    print(\"count_query_multilevel    ---> \"+ str(count_query_multilevel))\n",
    "    print(\"flag_get_in_subquery      ---> \"+ str(flag_get_in_subquery))\n",
    "    print(\"flag_lastjoin_is_subquery ---> \"+ str(flag_lastjoin_is_subquery))\n",
    "    print(\"flag_union_join_query     ---> \"+ str(flag_union_join_query))\n",
    "    '''\n",
    "    \n",
    "    '''Sección para los casos de UNION'''\n",
    "    if (flag_union_join_query and flag_get_in_subquery == False \\\n",
    "    and flag_lastjoin_is_subquery == False):\n",
    "        ## Si es = 1 entonces ponerle .1 , sino es sumarle 1 al ultimo valor  \n",
    "        \n",
    "        if (length_last_query == 1):\n",
    "            new_number_subquery = str(int(last_number_subquery) + 1)\n",
    "        else:\n",
    "            split               = last_number_subquery[:-1]\n",
    "            next_number         = int(last_number_subquery[-1]) + 1\n",
    "            new_number_subquery = split + str(next_number)\n",
    "\n",
    "        \n",
    "    elif (flag_union_join_query == False):\n",
    "        \n",
    "        '''Sección donde entra a las subqueries'''\n",
    "        ## Abre parentesis y consigue la primera subquery\n",
    "        if (flag_lastjoin_is_subquery == False):\n",
    "\n",
    "            if (length_last_query in [1,2] and flag_get_in_subquery):\n",
    "                entered_in_other_rule = True\n",
    "                new_number_subquery = generate_number_by_list(list_unique_str_num_query, last_number_subquery)\n",
    "\n",
    "            elif (length_last_query >= 3 and flag_get_in_subquery):\n",
    "                split               = last_number_subquery[:-1]\n",
    "                next_number         = int(last_number_subquery[-1]) + 1\n",
    "                new_number_subquery = split + str(next_number)\n",
    "\n",
    "            elif (length_last_query == count_query_multilevel):\n",
    "                new_number_subquery = str(last_number_subquery) + '.1'\n",
    "        \n",
    "\n",
    "        \n",
    "        '''Sección donde sale de las subqueries'''     \n",
    "        if (length_last_query >= 3 and flag_get_in_subquery == False):\n",
    "            # Se elimina el ultimo numero del multinivel para volver al principal del mismo\n",
    "            number_subquery_list = last_number_subquery.split('.')\n",
    "            number_subquery_list = number_subquery_list[:-1]\n",
    "            \n",
    "            for item in number_subquery_list:\n",
    "                if new_number_subquery == None:\n",
    "                    new_number_subquery = item\n",
    "                else:\n",
    "                    new_number_subquery = new_number_subquery + '.' + item\n",
    "        \n",
    "            entered_in_other_rule = True\n",
    "\n",
    "        elif (flag_lastjoin_is_subquery):\n",
    "            new_number_subquery = generate_number_by_list(list_unique_str_num_query, last_number_subquery)\n",
    "        \n",
    "        \n",
    "        if (length_last_query == count_query_multilevel and entered_in_other_rule == False):\n",
    "            new_number_subquery = str(last_number_subquery) + '.1'   \n",
    "            \n",
    "    return new_number_subquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_tables_and_columns(query):\n",
    "    \"\"\"\n",
    "    Función que obtiene todos los objetos de una query(tablas, campos, reglas) \n",
    "    \n",
    "    Descripción: Por cada nivel de subquery que consiga, inserta en un dataframe los \n",
    "    objetos que consiga según ese nivel.\n",
    "    \"\"\"    \n",
    "    \n",
    "    '''LISTAS Y MANEJO DE OBJETOS (TABLAS, CAMPOS Y REGLAS)'''  \n",
    "    \n",
    "    column                    = None # Contiene el último valor de un campo del ´SELECT´\n",
    "    \n",
    "    str_rule_agg              = '' # Cadena que va agregando la regla a medida que avanza el token\n",
    "    \n",
    "    tables                    = [] # Lista interna de tabla con formato [ESQUEMA, TABLA, ALIAS]\n",
    "    \n",
    "    column_list               = [] # Lista de columnas con formato [ESQUEMA.CAMPO1, ALIAS_1]\n",
    "    \n",
    "    column_list_internal      = [] # Lista de columnas con formato [ESQUEMA.CAMPO1, ALIAS_1]\n",
    "    \n",
    "    column_list_total         = [] # Lista total de todas las columnas con formato [ESQUEMA.CAMPO1, ALIAS_1]  \n",
    "                                   # Ej: [[ESQUEMA.CAMPO1, ALIAS_1],[ESQUEMA.CAMPO2, ALIAS_2] ]\n",
    "    \n",
    "    table_list                = [] # Lista interna de tabla con formato [ESQUEMA, TABLA, ALIAS] \n",
    "    \n",
    "    table_list_total          = [] # Lista total de todas las tablas encontradas en una query o subquery.     \n",
    "                                   # Ej: [[ESQUEMA1, TABLA1, ALIAS1],[ESQUEMA1, TABLA2, ALIAS2] ]\n",
    "                                   \n",
    "    rule_select_list          = [] # Lista interna de una regla o función encontrada en un SELECT.\n",
    "                                   # Con formato [str_rule_agg, column_alias]\n",
    "                                   # Ej: [MAX(COLUMN), ALIAS]\n",
    "    \n",
    "    rule_select_list_total    = [] # Lista total de todas las reglas y funciones encontradas en un SELECT\n",
    "                                   # Con formato [[str_rule_agg, column_alias],[str_rule_agg, column_alias]]\n",
    "                                   # Ej: [[MAX(CAMPO_1), ALIAS_1], [SUBSTR(CAMPO_2), ALIAS_2]]\n",
    "    \n",
    "    rule_generic_list_total   = [] # Lista total de todas las reglas encontradas en un ´JOIN´ o ´WHERE´\n",
    "    \n",
    "    \n",
    "    '''FLAGS PARA EL CONTROL DE LAS REGLAS INTERNAS'''\n",
    "    flag_rule_select           = False  # Se activa si consigue una funcion como regla [functions_sql]\n",
    "    flag_rule_filter           = False  # Se activa si consigue un ´ON´ o ´WHERE´\n",
    "    flag_end_rule_as           = False  # Se activa si es el final de una regla con un ALIAS cuando consigue ´AS´\n",
    "    flag_rule_case             = False  # Se activa si es el final de una regla de CASE cuando consigue ´END´ o ´AS´\n",
    "    flag_rule_case_internal    = False  # Se activa si es una regla de CASE dentro de otra función\n",
    "    flag_rule_in_before_select = False  # Se activa si consigue '(' después de un 'IN'\n",
    "        \n",
    "    flag_open_parentheses_rule = False  # Se activa cuando estoy dentro de una regla y consigue un parantesis ´(´\n",
    "    flag_count_parentheses_rule = False # Se activa cuando los parentesis abiertos y cerrados son iguales en una regla\n",
    "    \n",
    "    \n",
    "    '''MANEJO DEL TOKEN DE QUERY'''\n",
    "    last_keyword     = None     # Contiene el último valor del Keyword (palabra reservada SQL) del token \n",
    "    last_token       = None     # Contiene el último valor del token\n",
    "    subquery_alias   = None     # Contiene el ALIAS de una subquery\n",
    "    column_alias     = None     # Contiene el ALIAS de una subquery\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''VARIABLES PARA EXTRAER LAS TABLAS INPUT'''\n",
    "    dml_ddl_name      = None\n",
    "    not_get_from      = False\n",
    "    from_clausule     = False\n",
    "    flag_create_table = False\n",
    "    \n",
    "        \n",
    "    '''DATAFRAMES'''    \n",
    "    df_final_tables             = emptyDataframeTablesQuery(None)\n",
    "    df_internal_table           = emptyDataframeTablesQuery(None)\n",
    "    \n",
    "    df_final_columns            = emptyDataframeColumnsQuery(None)\n",
    "    df_internal_column          = emptyDataframeColumnsQuery(None)\n",
    "    \n",
    "    df_merge_table_column_input = emptyDataframeTablesColumnsInputQuery()\n",
    "    \n",
    "    \n",
    "    '''MULTINIVEL DE SUBQUERIES'''\n",
    "    flag_open_parentheses_subq  = False  # Se activa cuando se abre parentesis por una subquery\n",
    "    flag_close_parentheses_subq = False  # Se activa cuando se cierra parentesis por una subquery\n",
    "    flag_is_subquery            = False  # Se activa cuando consigue una subquery\n",
    "    flag_lastjoin_is_subquery   = False  # Se activa cuando hay una subquery dentro de otra subquery\n",
    "    num_query                   = 0      # Nivel del select o subquery.\n",
    "    \n",
    "    '''CONTADORES DE PARENTESIS PARA SABER CUANDO EMPIEZA O TERMINA UNA QUERY'''\n",
    "    count_query_multilevel     = 0  \n",
    "    count_open_parentheses     = 0        # Contador de parentesis '(' externos \n",
    "    count_close_parentheses    = 0        # Contador de parentesis ')' externos \n",
    "    count_open_parentheses_rule  = 0      # Contador de parentesis '(' de reglas \n",
    "    count_close_parentheses_rule = 0      # Contador de parentesis ')' de reglas\n",
    "    count_open_parentheses_internal  = 0  # Contador de parentesis '(' internos de una subquery\n",
    "    count_close_parentheses_internal = 0  # Contador de parentesis ')' internos de una subquery\n",
    "    \n",
    "    \n",
    "    list_unique_str_num_query  = set({'1'})\n",
    "    str_num_query              = '1'\n",
    "    last_number_subquery       = '1'\n",
    "    \n",
    "    \n",
    "    cast_data_type_list = ['INTEGER', 'CHAR', 'DECIMAL', 'VARCHAR','TIMESTAMP']\n",
    "        \n",
    "    stop_from_list = ['AS','CASE','WHEN','ON','AND','END','WHERE','GROUP','OVER','PARTITION','SET']\n",
    "    \n",
    "    functions_ignored = ['COUNT', 'MIN', 'MAX', 'SUM', 'FROM_UNIXTIME', 'DEC', 'QUALIFY',\n",
    "    'CAST', 'CONVERT', 'ZEROIFNULL','SUBSTR','SUBSTRING','ROW_NUMBER', 'RANK', 'ADD_MONTHS',\n",
    "    'COALESCE', 'CHAR', 'INTEGER', 'TRIM', 'OVER', 'FORMAT', 'DATE_FORMAT','CHARACTER_LENGTH',\n",
    "    'CHAR_LENGTH']\n",
    "    \n",
    "    dates_list = ['SECOND', 'MINUTE', 'HOUR', 'DAY', 'YEAR','MONTH','BOTH', 'TRAILING']\n",
    "    \n",
    "    columns_syntax_keywords = ['CURRENT_TIMESTAMP','CURRENT_TIME']\n",
    "    \n",
    "    # Lista de palabras reservadas que DEBEN ser consideras al obtener una regla.\n",
    "    keywords_ignored = ['AS', 'AND', 'OR', 'IN', 'IS', 'NOT','NOT NULL', 'NULL',\n",
    "    'LIKE', 'CASE', 'WHEN', 'ON', 'CURRENT_DATE']\n",
    "\n",
    "    # Lista de funciones reservadas de SQL ANSI\n",
    "    functions_sql = ['AVG', 'TITLE', 'OVER', 'OREPLACE','COUNT', 'MIN', 'MAX', 'SUM', \n",
    "    'FROM_UNIXTIME', 'DEC', 'CAST', 'CONVERT','ZEROIFNULL','SUBSTR','ROW_NUMBER','RANK',\n",
    "    'COALESCE', 'CHAR', 'TRIM', 'FORMAT', 'EXTRACT','ADD_MONTHS','DISTINCT', 'QUALIFY', \n",
    "    'DATE_FORMAT', 'ELSE', 'LAST_DAY', 'SUBSTRING', 'UPPER', 'TRUNC','CHARACTER_LENGTH'\n",
    "    ]\n",
    "    # quité el INTEGER de aqui\n",
    "    \n",
    "    # Lista de funciones reservadas de SQL ANSI para saber que comienza una regla\n",
    "    functions_rules = ['ON',  'WHERE']\n",
    "    \n",
    "    # Lista de funciones reservadas de SQL ANSI para saber que lo siguiente será un campo.\n",
    "    functions_before_column = ['SEL', 'SELECT', 'ON', 'END', 'THEN', 'DISTINCT', 'WHERE']\n",
    "    \n",
    "    # Lista de funciones reservadas de SQL ANSI para las uniones de tablas\n",
    "    table_syntax_joins = ['FROM', 'JOIN', 'INNER JOIN', 'LEFT JOIN', 'LEFT OUTER JOIN', \n",
    "\t'RIGHT JOIN', 'RIGHT OUTER JOIN','CROSS JOIN']\n",
    "    \n",
    "    union_joins_list = ['UNION', 'UNION ALL']\n",
    "        \n",
    "   \n",
    "    # Lista de sintaxis reservadas de SQL.     \n",
    "    table_syntax_keywords = [\n",
    "        # SELECT queries\n",
    "        'FROM', 'WHERE', 'JOIN', 'INNER JOIN', 'LEFT JOIN', 'LEFT OUTER JOIN', \n",
    "\t\t'RIGHT JOIN', 'RIGHT OUTER JOIN', 'ON', 'UNION', 'UNION ALL','CROSS JOIN',\n",
    "        # INSERT queries\n",
    "        'INTO', 'VALUES',\n",
    "        # UPDATE queries\n",
    "        'UPDATE', 'SET',\n",
    "        # Hive queries\n",
    "        'TABLE',  # INSERT TABLE\n",
    "    ]\n",
    "\n",
    "    for token in sqllib.get_query_tokens(query):\n",
    "                    \n",
    "        ## Homologar en caso que se consiga un 'SEL' en vez de 'SELECT'\n",
    "        if ((token.ttype is Name and token.value.upper() == 'SEL')):\n",
    "            token.ttype = DML\n",
    "            token.value = 'SELECT' \n",
    "        \n",
    "        if (count_open_parentheses > 0):\n",
    "            flag_is_subquery = True\n",
    "        \n",
    "\n",
    "        \n",
    "        ## Es una regla de IN con Subquery y no debe cortar el proceso.\n",
    "        if (token.value == '('):\n",
    "            if (last_token in ['IN', 'EXISTS', 'NOT EXISTS']):\n",
    "                flag_rule_in_before_select = True\n",
    "                    \n",
    "        \n",
    "        ## Cálculo de multiniveles de queries \n",
    "        if (flag_is_subquery):\n",
    "            if (token.value == '('):\n",
    "                count_open_parentheses += 1\n",
    "                    \n",
    "            elif (token.value == ')'):\n",
    "                count_close_parentheses += 1\n",
    "        \n",
    "        \n",
    "        ## Verifica si despues del IN viene un SELECT\n",
    "        if (flag_rule_in_before_select):\n",
    "            if(token.value == 'SELECT' and last_token == '('):\n",
    "                flag_rule_in_before_select = True\n",
    "            else:\n",
    "                flag_rule_in_before_select = False\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Una vez se consiga el fin de la subquery o UNION de querys, inserta en un df sus caracteristicas\n",
    "        if (token.ttype is Name and last_token in [')', 'AS']): \n",
    "            \n",
    "            ## Si los parentesis externos son iguales, es porque se cerró la subquery grande\n",
    "            if (count_open_parentheses == count_close_parentheses and \\\n",
    "                count_open_parentheses > 0):\n",
    "                \n",
    "                \n",
    "                # Obtiene el alias de la subquery\n",
    "                subquery_alias = token.value\n",
    " \n",
    "                # Obtiene el ultimo filtro que esté acumulado de la subquery\n",
    "                if (flag_rule_filter or flag_rule_select):\n",
    "                    flag_rule_filter  = False\n",
    "                    flag_rule_select  = False\n",
    "                    str_rule_agg = str_rule_agg.replace(\") \"+ last_token, '')\n",
    "                    rule_generic_list_total.append(str_rule_agg)\n",
    "                    str_rule_agg = ''\n",
    "                              \n",
    "                # Acumulación de objetos de tablas\n",
    "                \n",
    "                df_internal_table = insertDataframeTablesQuery(\n",
    "                                    df_internal_table, str_num_query,\n",
    "                                    table_list_total,subquery_alias ) \n",
    "                \n",
    "                df_final_tables   = df_final_tables.append(df_internal_table, ignore_index = True) \n",
    "                \n",
    "                \n",
    "                # Acumulación de objetos de campos y reglas internas\n",
    "                df_internal_column = insertDataframeColumnsQuery(\n",
    "                                    df_internal_column, str_num_query,\n",
    "                                    column_list, column_list_total, rule_select_list_total,\n",
    "                                    rule_generic_list_total)            \n",
    "                \n",
    "                df_final_columns = df_final_columns.append(df_internal_column, ignore_index = True) \n",
    "\n",
    "    \n",
    "                ## limpia los objetos en cada nivel de subselect\n",
    "                df_internal_table            = emptyDataframeTablesQuery(None)\n",
    "                df_internal_column           = emptyDataframeColumnsQuery(None)\n",
    "                column_list_total            = []                \n",
    "                column_list_internal         = []\n",
    "                table_list_total             = []\n",
    "                column_list                  = []\n",
    "                table_list                   = []\n",
    "                rule_select_list_total       = []\n",
    "                rule_generic_list_total      = []\n",
    "                column_alias = None\n",
    "                \n",
    "                \n",
    "                \n",
    "                '''   \n",
    "                print(\"count_open_parentheses  = \"+ str(count_open_parentheses))\n",
    "                print(\"count_close_parentheses = \"+ str(count_close_parentheses))\n",
    "                print(\"count_open_parentheses_internal  = \" + str(count_open_parentheses_internal))\n",
    "                print(\"count_close_parentheses_internal = \" + str(count_close_parentheses_internal))\n",
    "                print(\"flag_open_parentheses_subq = \" + str(flag_open_parentheses_subq))\n",
    "                \n",
    "                print(\"ANTES DE ENTRAR generateNumberedListSubquery 1\")\n",
    "                ''' \n",
    "                \n",
    "                flag_is_subquery            = False \n",
    "                not_get_from                = False\n",
    "                flag_rule_in                = False                \n",
    "                flag_rule_case              = False\n",
    "                flag_rule_case_internal     = False\n",
    "                flag_open_parentheses_subq  = False   \n",
    "                flag_close_parentheses_subq = True\n",
    "                count_open_parentheses      = 0\n",
    "                count_close_parentheses     = 0  \n",
    "                count_open_parentheses_rule  = 0\n",
    "                count_close_parentheses_rule = 0\n",
    "                \n",
    "                    \n",
    "                str_num_query = generateNumberedListSubquery(False,\n",
    "                                                             flag_lastjoin_is_subquery,\n",
    "                                                             False,\n",
    "                                                             count_query_multilevel,\n",
    "                                                             str_num_query,\n",
    "                                                             list_unique_str_num_query) \n",
    "                \n",
    "                if (str_num_query == None):\n",
    "                    str_num_query = '1'\n",
    "                    \n",
    "                last_number_subquery  =   str_num_query \n",
    "                list_unique_str_num_query.add(str_num_query)\n",
    "                \n",
    "            \n",
    "                \n",
    "        ## Cálculo de multiniveles de queries internas (subquery dentro de subquery)\n",
    "        if (flag_lastjoin_is_subquery and len(str_num_query) > 3 and flag_open_parentheses_subq):\n",
    "            \n",
    "            if (token.value == '('):\n",
    "                count_open_parentheses_internal += 1\n",
    "            elif (token.value == ')'):\n",
    "                count_close_parentheses_internal += 1\n",
    "         \n",
    "            if (token.ttype is Name and last_token == ')'):   \n",
    "                if ((count_open_parentheses_internal == count_close_parentheses_internal and \\\n",
    "                    count_open_parentheses_internal > 0 and flag_open_parentheses_subq) or \\\n",
    "                    (count_open_parentheses-1 == count_close_parentheses)):\n",
    "                    \n",
    "                    '''\n",
    "                    if(count_open_parentheses-1 == count_close_parentheses):\n",
    "                        print(\"DETENERSE EN ESTE PUNTO !!! \")\n",
    "                    '''\n",
    "                    \n",
    "                    # Obtiene el ultimo filtro que esté acumulado de la subquery\n",
    "                    if (flag_rule_filter and last_keyword != 'ROW_NUMBER'):\n",
    "                        flag_rule_filter = False\n",
    "                        str_rule_agg = str_rule_agg.replace(\") \"+ last_token, '')\n",
    "                        rule_generic_list_total.append(str_rule_agg)\n",
    "                        str_rule_agg = ''\n",
    "                    \n",
    "                    \n",
    "                    # Acumulación de objetos de tablas\n",
    "                    df_internal_table = insertDataframeTablesQuery(\n",
    "                                        df_internal_table, str_num_query,\n",
    "                                        table_list_total,subquery_alias ) \n",
    "\n",
    "                    df_final_tables   = df_final_tables.append(df_internal_table, ignore_index = True) \n",
    "\n",
    "\n",
    "                    # Acumulación de objetos de campos y reglas internas\n",
    "                    df_internal_column = insertDataframeColumnsQuery(\n",
    "                                        df_internal_column, str_num_query,\n",
    "                                        column_list, column_list_total, rule_select_list_total,\n",
    "                                        rule_generic_list_total)            \n",
    "\n",
    "                    df_final_columns = df_final_columns.append(df_internal_column, ignore_index = True) \n",
    "\n",
    "\n",
    "                    ## limpia los objetos en cada nivel de subselect\n",
    "                    df_internal_table            = emptyDataframeTablesQuery(None)\n",
    "                    df_internal_column           = emptyDataframeColumnsQuery(None)\n",
    "                    column_list_total            = []\n",
    "                    column_list_internal         = []\n",
    "                    table_list_total             = []\n",
    "                    column_list                  = []\n",
    "                    table_list                   = []\n",
    "                    rule_select_list_total       = []\n",
    "                    rule_generic_list_total      = []\n",
    "                    flag_rule_filter             = False              \n",
    "                    flag_rule_case               = False\n",
    "                    flag_rule_case_internal      = False\n",
    "                    not_get_from                 = False\n",
    "                                        \n",
    "                    '''\n",
    "                    print(\"count_open_parentheses  = \"+ str(count_open_parentheses))\n",
    "                    print(\"count_close_parentheses = \"+ str(count_close_parentheses))\n",
    "                    print(\"count_open_parentheses_internal  = \" + str(count_open_parentheses_internal))\n",
    "                    print(\"count_close_parentheses_internal = \" + str(count_close_parentheses_internal))\n",
    "                    print(\"flag_open_parentheses_subq = \" + str(flag_open_parentheses_subq))\n",
    "                    '''\n",
    "                    \n",
    "                    count_open_parentheses_internal  = 0\n",
    "                    count_close_parentheses_internal = 0  \n",
    "                    count_open_parentheses_rule  = 0\n",
    "                    count_close_parentheses_rule = 0\n",
    "                    flag_close_parentheses_subq      = True\n",
    "\n",
    "                    \n",
    "                    str_num_query = generateNumberedListSubquery(False,\n",
    "                                                                 flag_lastjoin_is_subquery,\n",
    "                                                                 False,\n",
    "                                                                 count_query_multilevel,\n",
    "                                                                 str_num_query,\n",
    "                                                                 list_unique_str_num_query) \n",
    "\n",
    "                    \n",
    "                    last_number_subquery  =   str_num_query \n",
    "                    list_unique_str_num_query.add(str_num_query)\n",
    "  \n",
    "            \n",
    "        ## Se insertan los ultimos campos y tablas encontrados, antes de un subselect o fin de la query.\n",
    "        if ((token.ttype is DML and token.value.upper() == 'SELECT'\\\n",
    "          or token.ttype is Punctuation and token.value == ';') and \\\n",
    "            flag_rule_in_before_select == False and \\\n",
    "            flag_rule_select == False and \\\n",
    "           (last_token not in functions_rules or last_keyword not in functions_rules)):       \n",
    "                \n",
    "            if (num_query > 0):  \n",
    "                \n",
    "                # Para los casos que vengan consultas con UNION\n",
    "                if (last_token in union_joins_list):\n",
    "                    last_number_subquery = str_num_query\n",
    "                    str_num_query = generateNumberedListSubquery(False,\n",
    "                                                                 False,\n",
    "                                                                 True,\n",
    "                                                                 count_query_multilevel,\n",
    "                                                                 str_num_query,\n",
    "                                                                 list_unique_str_num_query) \n",
    "                \n",
    "                # Calcular el multinivel siempre que entra a la subquery\n",
    "                if (last_token == '(' and last_keyword in table_syntax_joins):\n",
    "                \n",
    "                    \n",
    "                    flag_is_subquery = True\n",
    "                    flag_open_parentheses_subq = True\n",
    "                        \n",
    "                        \n",
    "                    if(len(str_num_query) >= 3):\n",
    "                        flag_lastjoin_is_subquery = True\n",
    "                    \n",
    "                    if(count_open_parentheses == 0):\n",
    "                        count_open_parentheses += 1\n",
    "                        \n",
    "                    count_query_multilevel += 1\n",
    "                    \n",
    "                    ## Comienza contador de parentesis interno de la subquery\n",
    "                    if (flag_lastjoin_is_subquery and len(str_num_query) > 1):\n",
    "                        \n",
    "                        ## Query de más afuera donde sería la principal y acumula esos parentesis\n",
    "                        if (len(str_num_query) > 3):\n",
    "                            count_open_parentheses_internal  = 0\n",
    "                            count_close_parentheses_internal = 0 \n",
    "                        \n",
    "                        count_open_parentheses_internal += 1\n",
    "                    \n",
    "                    last_number_subquery  =   str_num_query   \n",
    "                    '''\n",
    "                    print(\"EL ESTADO DE LOS PARENTESIS ES = \")\n",
    "                    print(\"count_open_parentheses  = \"+ str(count_open_parentheses))\n",
    "                    print(\"count_close_parentheses = \"+ str(count_close_parentheses))\n",
    "                    print(\"ANTES DE ENTRAR generateNumberedListSubquery 3\")\n",
    "                    '''\n",
    "                    str_num_query = generateNumberedListSubquery(True,\n",
    "                                                                 flag_lastjoin_is_subquery,\n",
    "                                                                 False,\n",
    "                                                                 count_query_multilevel,\n",
    "                                                                 str_num_query,\n",
    "                                                                 list_unique_str_num_query) \n",
    "                   \n",
    "                    \n",
    "                    list_unique_str_num_query.add(str_num_query)\n",
    "                    \n",
    "            if (last_token not in functions_rules):\n",
    "                last_keyword = 'SELECT'  \n",
    "           \n",
    "                \n",
    "            num_query += 1            \n",
    "            #Omite el 'SELECT' principal\n",
    "            if (num_query >= 2):                \n",
    " \n",
    "                # Obtiene el ultimo filtro que esté acumulado de la subquery\n",
    "                if (token.ttype is Punctuation and token.value == ';' and flag_rule_filter):\n",
    "                    flag_rule_filter  = False\n",
    "                    flag_rule_select  = False\n",
    "                    rule_generic_list_total.append(str_rule_agg)\n",
    "                    str_rule_agg = ''\n",
    "                    \n",
    "                    \n",
    "                # Acumulación de objetos de tablas\n",
    "                df_internal_table = insertDataframeTablesQuery(\n",
    "                                    df_internal_table, last_number_subquery,\n",
    "                                    table_list_total,subquery_alias ) \n",
    "                \n",
    "                df_final_tables   = df_final_tables.append(df_internal_table, ignore_index = True) \n",
    "                \n",
    "                \n",
    "                # Acumulación de objetos de campos y reglas internas\n",
    "                df_internal_column = insertDataframeColumnsQuery(\n",
    "                                    df_internal_column, last_number_subquery,\n",
    "                                    column_list, column_list_total, rule_select_list_total,\n",
    "                                    rule_generic_list_total)            \n",
    "                \n",
    "                df_final_columns = df_final_columns.append(df_internal_column, ignore_index = True) \n",
    "\n",
    "    \n",
    "                ## limpia los objetos en cada nivel de subselect\n",
    "                df_internal_table            = emptyDataframeTablesQuery(None)\n",
    "                df_internal_column           = emptyDataframeColumnsQuery(None)\n",
    "                column_list_total            = []                \n",
    "                table_list_total             = []\n",
    "                column_list_internal         = []\n",
    "                column_list                  = []\n",
    "                table_list                   = []\n",
    "                rule_select_list_total       = []\n",
    "                rule_generic_list_total      = []\n",
    "                str_rule_agg = ''\n",
    "                flag_is_subquery             = True\n",
    "                flag_rule_filter             = False\n",
    "                not_get_from                 = False\n",
    "    \n",
    "        #print(['1', '***  ' + str(str_num_query)  + '  ***', token, token.ttype, last_token, last_keyword])              \n",
    "        \n",
    "    \n",
    "    ####################### EXTRACCIÓN DE LOGICAS DE CODIGO ########################################\n",
    "        '''\n",
    "        Sección que recupera las reglas internas y los filtros de una query,\n",
    "        junto con sus alias respectivos\n",
    "        Retorna una lista con el formato: [str_rule_agg, column_alias]\n",
    "        A su vez si inserta en una lista        \n",
    "        ''' \n",
    "\n",
    "        '''\n",
    "        print(\"flag_is_subquery              = \" + str(flag_is_subquery))\n",
    "        print(\"not_get_from                  = \" + str(not_get_from))\n",
    "        print(\"flag_rule_filter              = \" + str(flag_rule_filter))\n",
    "        print(\"flag_rule_select              = \" + str(flag_rule_select))\n",
    "        print(\"flag_end_rule_as              = \" + str(flag_end_rule_as))\n",
    "        print(\"flag_rule_case                = \" + str(flag_rule_case))\n",
    "        print(\"flag_rule_case_internal       = \" + str(flag_rule_case_internal)) \n",
    "        print(\"flag_rule_in_before_select    = \" + str(flag_rule_in_before_select))       \n",
    "        print(\"count_open_parentheses        = \" + str(count_open_parentheses))\n",
    "        print(\"count_close_parentheses       = \" + str(count_close_parentheses))\n",
    "        print(\"flag_open_parentheses_rule    = \" + str(flag_open_parentheses_rule)+ \"\\n\" )\n",
    "        print(\"count_open_parentheses_rule   = \" + str(count_open_parentheses_rule))\n",
    "        print(\"count_close_parentheses_rule  = \" + str(count_close_parentheses_rule)) \n",
    "        print(\"flag_count_parentheses_rule   = \" + str(flag_count_parentheses_rule))             \n",
    "        '''\n",
    "        \n",
    "        # Para los casos que toma el subquery_alias como column_alias y continua con algun JOIN\n",
    "        token_value_clean = \" \".join(token.value.upper().split())        \n",
    "        if (token_value_clean in table_syntax_joins and \\\n",
    "            column_alias == last_token):\n",
    "            #print(\"Quitar el alias de la regla = \"+ column_alias)\n",
    "            column_alias = None\n",
    "            \n",
    "        \n",
    "\n",
    "        ##CASE, ON, FUNCTIONS_SQL   \n",
    "        if ((token.value.upper() in keywords_ignored or token.value.upper() in functions_sql) \\\n",
    "            and flag_rule_filter == False \n",
    "            and flag_rule_select == False):\n",
    "            \n",
    "            flag_rule_case_internal = False\n",
    "            \n",
    "            \n",
    "            if (token.value.upper() in ['CASE']): \n",
    "                flag_rule_case   = True\n",
    "                flag_rule_select = True                \n",
    "                                               \n",
    "            elif (token.value.upper() in ['ON','QUALIFY']):         \n",
    "                flag_rule_filter = True  \n",
    "                \n",
    "            elif (token.value.upper() in functions_sql and flag_rule_filter == False):          \n",
    "                flag_rule_select = True  \n",
    "            elif (token.value.upper() == 'NULL'and (last_token == ',' or last_keyword == 'SELECT')):        \n",
    "                flag_rule_select = True  \n",
    " \n",
    "        elif (flag_rule_select and token.value.upper() in ['CASE']):  \n",
    "            flag_rule_case_internal   = True \n",
    "            \n",
    "            \n",
    "        elif (token.value.upper() in ['CASE']):  \n",
    "            flag_rule_case   = True \n",
    "        \n",
    "        \n",
    "        ## Casos de campos constantes. Ejemplo: 'Clientes Con Campana' (Varchar(50)) Descripcion \n",
    "        elif ((token.ttype is Literal.String.Single or \\\n",
    "               token.ttype is Literal.Number.Integer)\n",
    "              and flag_rule_filter == False  \\\n",
    "              and flag_rule_select == False  \\\n",
    "              and (last_token == ',' or last_keyword == 'SELECT') ):    \n",
    "            flag_rule_select = True  \n",
    "        \n",
    "        \n",
    "        # Para concluir los casos de CAST ('' AS CHAR(40)) AS ALIAS_CAMPO\n",
    "        # Y cualquier otro ALIAS de campos en general\n",
    "        elif (token.is_keyword and token.value.upper() == 'AS' \\\n",
    "            and last_token in [')', 'END',\"'\"+'0000'+\"'\"] ):\n",
    "        \n",
    "            if (count_open_parentheses_rule == 0):\n",
    "                flag_end_rule_as = True\n",
    "            else:\n",
    "                flag_end_rule_as = False\n",
    "            \n",
    "            if (last_token == 'END' and last_keyword == 'END' and count_open_parentheses_rule == 0):\n",
    "                flag_rule_select = False                  \n",
    "                flag_rule_case   = False\n",
    "        \n",
    "           \n",
    "        \n",
    "        ## No interrumpir la acumulacion de logica asi consiga ',' \n",
    "        ## Si no hay conseguido AS, si no es un filtro, si hay un parentesis abiertos '('\n",
    "        elif ((token.ttype is Punctuation and token.value == ',' or \\\n",
    "              token.ttype is Name and token.value.upper() not in functions_sql) \\\n",
    "            and str_rule_agg != ''  \\\n",
    "            and flag_end_rule_as == False \\\n",
    "            and flag_rule_filter == False \\\n",
    "            and flag_open_parentheses_rule == False):\n",
    "            \n",
    "\n",
    "            if (flag_rule_case and last_keyword == 'END' \\\n",
    "            and flag_rule_case_internal == False):\n",
    "                flag_rule_case = False\n",
    "            \n",
    "            \n",
    "            # Para los casos por ejemplo: MAX(CASE WHEN RNK=1 THEN XCTA END) NTRJ1\n",
    "            if (flag_rule_case_internal and last_keyword == 'END' \\\n",
    "            and count_open_parentheses_rule == 0):\n",
    "                flag_rule_case_internal = False\n",
    "            \n",
    "            \n",
    "            ## Fin de reglas en el SELECT\n",
    "            if (flag_rule_case == False and flag_rule_case_internal == False\n",
    "               and count_open_parentheses_rule == 0 ):\n",
    "                \n",
    "                if(token.ttype is Name and last_token in [')','AS'] \\\n",
    "                and last_keyword not in ['ANY','BY','DESC']):\n",
    "                    column_alias = token.value.upper()\n",
    "                \n",
    "                flag_rule_select = False \n",
    "                rule_select_list = [str_rule_agg, column_alias]\n",
    "                rule_select_list_total.append(rule_select_list)\n",
    "                str_rule_agg = ''                \n",
    "                count_open_parentheses_rule  = 0\n",
    "                count_close_parentheses_rule = 0\n",
    "                flag_count_parentheses_rule = False\n",
    "                last_keyword = 'SELECT'\n",
    "         \n",
    "       ## Fin del ON o WHERE         \n",
    "        elif ((flag_rule_filter and token.value.upper() in table_syntax_keywords \\\n",
    "              and token.value.upper() != 'FROM' and flag_rule_in_before_select == False)\\\n",
    "              or (token.ttype is Punctuation and token.value in [';'])):\n",
    "            \n",
    "                flag_rule_filter = False\n",
    "                str_rule_agg = str_rule_agg.replace(\") \"+ last_token, '')\n",
    "                rule_generic_list_total.append(str_rule_agg)\n",
    "                str_rule_agg = ''\n",
    "                count_open_parentheses_rule  = 0\n",
    "                count_close_parentheses_rule = 0\n",
    "                flag_count_parentheses_rule = False\n",
    "                \n",
    "        elif token.ttype is Name:\n",
    "            \n",
    "            ## Para los casos que el campo sea 'srvaprimo' Submit_User,\n",
    "            if (str_rule_agg.strip() == last_token and \\\n",
    "                str_rule_agg.strip() not in functions_sql and \\\n",
    "                str_rule_agg.strip() not in functions_before_column and \\\n",
    "                str_rule_agg.strip() not in keywords_ignored and \\\n",
    "                flag_rule_filter == False):  \n",
    "                column_alias = token.value                 \n",
    "        \n",
    "          \n",
    "            ## Tomar el alias de la regla \n",
    "            if(flag_count_parentheses_rule and flag_rule_case == False \\\n",
    "            and token.value != subquery_alias \\\n",
    "            and (flag_rule_filter == False and flag_rule_select == False) \\\n",
    "            and last_token not in ['SELECT','AND','ON', '(', '.', '=', '+', '*',',']):\n",
    "                \n",
    "                #column_alias = last_token\n",
    "                column_alias = token.value                \n",
    "                flag_count_parentheses_rule = False                \n",
    "                \n",
    "            ## Fin del CASE con ALIAS y sin tener referencia de AS\n",
    "            if (last_token == 'END' and last_keyword == 'END'):  \n",
    "                last_token = 'AS'\n",
    "                flag_end_rule_as = True\n",
    "                flag_rule_case   = False\n",
    "            \n",
    "            \n",
    "            ## Fin de la regla con ALIAS y con AS\n",
    "            if (last_token == 'AS' and flag_count_parentheses_rule and token.value != subquery_alias):\n",
    "                column_alias = token.value\n",
    "                flag_end_rule_as = True\n",
    "            \n",
    "            \n",
    "            ## Fin del CASE con ALIAS y con AS\n",
    "            if (last_token == 'AS' and flag_end_rule_as and last_keyword != 'TABLE'):\n",
    "                \n",
    "                flag_end_rule_as = False\n",
    "                \n",
    "                # Para Ignorar los casos de CAST ('' AS CHAR(40)) AS ALIAS_CAMPO\n",
    "                if (token.value.upper() not in cast_data_type_list and token.value != subquery_alias):\n",
    "                    flag_rule_select = False\n",
    "                    column_alias     = token.value\n",
    "                    rule_select_list = [str_rule_agg, column_alias]\n",
    "                    rule_select_list_total.append(rule_select_list)\n",
    "                    \n",
    "                    str_rule_agg = ''\n",
    "                    count_open_parentheses_rule  = 0\n",
    "                    count_close_parentheses_rule = 0\n",
    "                    flag_count_parentheses_rule = False\n",
    "                    last_keyword = 'SELECT'\n",
    "                \n",
    "\n",
    "        # Para la ultima logica antes del FROM, si no tiene un AS\n",
    "        elif (flag_rule_select and token.value == 'FROM' \\\n",
    "              and last_token not in dates_list \\\n",
    "              and flag_rule_filter == False \\\n",
    "              and count_open_parentheses_rule == 0 \\\n",
    "              and token.value != subquery_alias):\n",
    "            \n",
    "            flag_rule_select = False\n",
    "            \n",
    "            column_alias     = last_token\n",
    "            \n",
    "            str_rule_agg = str_rule_agg.replace(column_alias, '')\n",
    "            \n",
    "            rule_select_list = [str_rule_agg, column_alias]\n",
    "            rule_select_list_total.append(rule_select_list)\n",
    "            str_rule_agg = ''          \n",
    "            count_open_parentheses_rule  = 0\n",
    "            count_close_parentheses_rule = 0\n",
    "            flag_count_parentheses_rule = False    \n",
    "            \n",
    "            \n",
    "        ## Apertura del WHERE, ON para los casos que vienen uno seguido de otro.\n",
    "        if (((token.is_keyword and token.value.upper() in functions_rules) or \\\n",
    "            (token is Name and token.value.upper() in functions_rules)) and \\\n",
    "            flag_rule_select == False):     \n",
    "            flag_rule_filter = True  \n",
    "\n",
    "            if (column_alias == last_token):\n",
    "                column_alias = None\n",
    "                \n",
    "        \n",
    "        \n",
    "        # Contar los parentesis de las reglas en un SELECT    \n",
    "        if flag_rule_select:\n",
    "            if (token.value == '('):\n",
    "                count_open_parentheses_rule += 1\n",
    "            elif (token.value == ')'):\n",
    "                count_close_parentheses_rule += 1\n",
    "                \n",
    "            if (count_open_parentheses_rule == count_close_parentheses_rule and \\\n",
    "                count_open_parentheses_rule > 0):\n",
    "                \n",
    "                flag_count_parentheses_rule = True\n",
    "                count_open_parentheses_rule  = 0\n",
    "                count_close_parentheses_rule = 0\n",
    "\n",
    "        \n",
    " \n",
    "        ## ACUMULADO DE TEXTO REGLA INTERNA\n",
    "        if ((flag_rule_select or flag_rule_filter) \\\n",
    "            and flag_end_rule_as == False and token.value != column_alias):\n",
    "            \n",
    "            if (token.ttype is Punctuation and token.value == '.'):\n",
    "                str_rule_agg = str_rule_agg + '.'\n",
    "                \n",
    "            elif (last_token in ['.']):\n",
    "                str_rule_agg = str_rule_agg + token.value \n",
    "                \n",
    "            elif (token.is_keyword and token.value.upper() in functions_rules):\n",
    "                str_rule_agg = str_rule_agg + ' '+ token.value \n",
    "                            \n",
    "            elif (token.ttype is not Text.Whitespace.Newline):\n",
    "                str_rule_agg = str_rule_agg + ' '+ token.value\n",
    "                \n",
    "                if (token.value == '('):\n",
    "                    flag_open_parentheses_rule = True \n",
    "                elif (token.value == ')'):\n",
    "                    flag_open_parentheses_rule = False \n",
    "                  \n",
    "  \n",
    "        #print(\"\\n\\n ACUMULADO DE TEXTO REGLA INTERNA =>\"+ str_rule_agg)\n",
    "        \n",
    "                \n",
    "    \n",
    "    #######################  EXTRACCIÓN DE CAMPOS ########################################\n",
    "        '''\n",
    "        Sección que recupera los campos usados tanto en el SELECT como en los WHERE, ON \n",
    "        Retorna una lista con el formato: [CAMPO, ALIAS]\n",
    "        '''\n",
    "        if (token.ttype is Punctuation and last_token in functions_sql):\n",
    "            last_keyword = last_token\n",
    "        \n",
    "\n",
    "        # Para los casos que los campos sean 'CURRENT_TIME', etc\n",
    "        if token.is_keyword and token.value.upper() in columns_syntax_keywords \\\n",
    "           and flag_rule_select == False and flag_rule_filter == False:\n",
    "            column = token.value.upper()\n",
    "            column_list.append(column)\n",
    "\n",
    "        elif token.is_keyword and token.value.upper() not in keywords_ignored:\n",
    "            # mantiene el nombre del último valor de last keyword, ej: SELECT, FROM, WHERE, (ORDER) BY\n",
    "            last_keyword = token.value.upper()\n",
    "\n",
    "            \n",
    "        elif token.ttype is Name and token.value not in functions_sql:\n",
    "            # analiza los nombres de tokens, los nombres de columna y los valores de condiciones\n",
    "            \n",
    "            \n",
    "            if (last_keyword in functions_before_column or last_keyword in functions_sql) \\\n",
    "               and (last_token not in ['AS'] or last_token in [',']):\n",
    "                \n",
    "                                \n",
    "                if token.value.upper() not in functions_sql and \\\n",
    "                   token.value.upper() not in cast_data_type_list and \\\n",
    "                   token.value.upper() != 'FROM':\n",
    "                    \n",
    "                    if str(last_token) == '.':\n",
    "\n",
    "                        # we have table.column notation example\n",
    "                        # append column name to the last entry of columns\n",
    "                        # as it is a table name in fact\n",
    "                        table_name = column_list[-1]\n",
    "                        column_list[-1] = '{}.{}'.format(table_name, token)\n",
    "                        column = column_list[-1]\n",
    "\n",
    "                    elif last_token in ['AND'] and last_keyword == 'THEN':\n",
    "                        column = str(token.value)\n",
    "                        column_list.append(column)\n",
    "                        \n",
    "                    ## alias de campos. Ejemplo: A.Monthly_Target_Cd Monthly_Target_Cd\n",
    "                    elif ((str(column).upper() == last_token or token.value.upper() == last_token) \\\n",
    "                       and last_keyword == 'SELECT'):\n",
    "                        column_alias = token.value\n",
    "                        column_list_internal = [column, column_alias]\n",
    "                        column_alias = None\n",
    "\n",
    "                    elif (str(token.value) != subquery_alias and \\\n",
    "                          str(token.value) != column_alias ):\n",
    "                        \n",
    "                        column = str(token.value)\n",
    "                        column_list.append(column)\n",
    "                  \n",
    "            ## alias de campos      \n",
    "            elif (last_keyword in functions_before_column \\\n",
    "                    or last_keyword in functions_sql) \\\n",
    "                    and (last_token in ['AS'] or last_token in [',']) \\\n",
    "                    and token.value.upper() not in functions_sql: \n",
    "                column_alias = token.value\n",
    "                column_list_internal = [column, column_alias]\n",
    "                column_alias = None\n",
    "\n",
    "                    \n",
    "            elif last_keyword in ['INTO'] and token.ttype is Punctuation: #and last_token.ttype is Punctuation:\n",
    "                # INSERT INTO `foo` (col1, `col2`) VALUES (..)\n",
    "                column = str(token.value).strip('`')     \n",
    "                column_list.append(column) \n",
    "                \n",
    "        elif token.ttype is Wildcard:\n",
    "            # handle * wildcard in SELECT part, but ignore count(*)\n",
    "            # print(last_keyword, last_token, token.value)\n",
    "            if last_keyword == 'SELECT' and last_token != '(':\n",
    "                if str(last_token) == '.':\n",
    "                    # handle SELECT foo.*\n",
    "                    table_name = column_list[-1]\n",
    "                    column_list[-1] = '{}.{}'.format(table_name, str(token))\n",
    "                    column = column_list[-1]                    \n",
    "                else:\n",
    "                    column = str(token.value)  \n",
    "                    column_list.append(column)\n",
    "                    \n",
    "        length_list_column = len(column_list_internal)\n",
    "        \n",
    "        \n",
    "        if (length_list_column >= 1 and (column_list_internal not in column_list_total)):\n",
    "            column_list_total.append(column_list_internal)\n",
    "            column = None\n",
    "            column_alias = None\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    ####################### EXTRACCIÓN DE TABLAS  ####################################        \n",
    "        '''\n",
    "        Sección que recupera las tablas de una query \n",
    "        Retorna una lista con el formato: [esquema, tabla, alias]\n",
    "        '''  \n",
    "        \n",
    "        subquery_alias    = None\n",
    "        token_value_clean = \" \".join(token.value.upper().split())\n",
    "        \n",
    "        if (token.ttype is DML or token.ttype is DDL):\n",
    "            dml_ddl_name = token.value.upper()  \n",
    "            from_clausule = False \n",
    "            \n",
    "            if(dml_ddl_name == 'CREATE'):\n",
    "                flag_create_table = True\n",
    "            \n",
    "            if(dml_ddl_name == 'SELECT' and flag_create_table):\n",
    "                flag_create_table = False\n",
    "                \n",
    "        \n",
    "        if token.ttype is Punctuation and token.value == ',' \\\n",
    "            and from_clausule == True:\n",
    "            last_keyword = 'FROM'\n",
    "        \n",
    "        if token.is_keyword and from_clausule == True and \\\n",
    "           token.value.upper() in stop_from_list:            \n",
    "            from_clausule = False\n",
    "            last_keyword = None\n",
    "        \n",
    "        \n",
    "        ## Para los casos de cerrar algunos campos en el SELECT que llaman a FROM\n",
    "        if (token.is_keyword and token.value.upper() == 'AS' \\\n",
    "           and last_token == ')' and not_get_from):\n",
    "            last_keyword = 'SELECT'\n",
    "            not_get_from = False\n",
    "            \n",
    "        \n",
    "\n",
    "        if token.is_keyword and token.value.upper() in table_syntax_keywords:\n",
    "            # keep the name of the last keyword, the next one can be a table name\n",
    "            last_keyword = \" \".join(token.value.upper().split())\n",
    "            \n",
    "            ## Para los casos de algunos campos en el SELECT que llaman a FROM\n",
    "            if token.value.upper() == 'FROM' and last_token in dates_list:\n",
    "                not_get_from = True\n",
    "                \n",
    "            elif(token.value.upper() == 'FROM' and not_get_from == True):\n",
    "                not_get_from = False\n",
    "                \n",
    "            ## Para los casos de que las tablas estén separadas por ,    \n",
    "            elif(token.value.upper() == 'FROM' and last_token in [\"'\"+'0'+\"'\"]):\n",
    "                from_clausule = False\n",
    "                not_get_from  = True\n",
    "\n",
    "            elif(token.value.upper() == 'FROM' and last_token not in[\"'\"+'0'+\"'\"]):\n",
    "                from_clausule = True\n",
    "\n",
    "                \n",
    "            elif(token.value.upper() in ['WHERE','GROUP']):\n",
    "                from_clausule = False\n",
    "                    \n",
    "        \n",
    "                    \n",
    "        elif str(token) == '(' and last_token not in functions_sql:\n",
    "            # reset the last_keyword for INSERT `foo` VALUES(id, bar) ...\n",
    "            #last_keyword = None\n",
    "            pass\n",
    "        elif token.is_keyword and str(token) in ['FORCE', 'ORDER']:\n",
    "            # reset the last_keyword for \"SELECT x FORCE INDEX\" queries and \"SELECT x ORDER BY\"\n",
    "            last_keyword = None\n",
    "        elif token.is_keyword and str(token) == 'SELECT' and last_keyword in ['INTO', 'TABLE']:\n",
    "            # reset the last_keyword for \"INSERT INTO SELECT\" and \"INSERT TABLE SELECT\" queries\n",
    "            last_keyword = None\n",
    "        elif token.ttype is Name or token.is_keyword:\n",
    "            # print([last_keyword, last_token, token.value])\n",
    "            # analyze the name tokens, column names and where condition values\n",
    "\n",
    "            if token.ttype is Name and token.value in functions_ignored \\\n",
    "               and from_clausule == True :\n",
    "                not_get_from = True\n",
    "                    \n",
    "                  \n",
    "\n",
    "            ## De esta lista quité el 'INTO'\n",
    "            if last_keyword in ['FROM', 'JOIN', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', \n",
    "                                'LEFT OUTER JOIN','RIGHT OUTER JOIN', 'UPDATE', 'TABLE'] \\\n",
    "                and last_token not in ['AS', 'CREATE'] \\\n",
    "                and token.value not in ['AS', 'SELECT'] \\\n",
    "                and not_get_from == False \\\n",
    "                and flag_create_table == False \\\n",
    "                and flag_rule_filter == False:\n",
    "\n",
    "                if last_token == '.':\n",
    "                    # we have database.table notation example\n",
    "                    # append table name to the last entry of tables\n",
    "                    # as it is a database name in fact\n",
    "                    if (len(tables) >= 1):\n",
    "\n",
    "                        database_name = tables[-1]\n",
    "                        table = token.value\n",
    "                        tables[-1] = '{}.{}'.format(database_name, token)\n",
    "                        last_keyword = 'TABLE' #None\n",
    "                        table_list = [database_name, table]\n",
    "                        \n",
    "                        if (dml_ddl_name not in ['DROP']):\n",
    "                            table_list_total.append(table_list)\n",
    "                    \n",
    "                elif last_token not in [',', last_keyword] and last_token not in ['ON', last_keyword]:\n",
    "                    # it's not a list of tables, e.g. SELECT * FROM foo, bar\n",
    "                    # hence, it can be the case of alias without AS, e.g. SELECT * FROM foo bar\n",
    "                    alias_table = token.value\n",
    "                    table_list.append(alias_table)\n",
    "\n",
    "                else: ## database schema\n",
    "                    table_name = str(token.value.strip('`'))\n",
    "                    tables.append(table_name)\n",
    "\n",
    "        length_list_table = len(table_list)\n",
    "\n",
    "        if (length_list_table >= 2 and (table_list not in table_list_total)):\n",
    "            table_list_total.append(table_list)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #Variables que acumulan ultimos valores del token y ayudan a analizar la query\n",
    "        flag_lastjoin_is_subquery = flag_open_parentheses_subq\n",
    "    \n",
    "        if (token.ttype is Text.Whitespace.Newline):\n",
    "            last_token = last_token.upper() \n",
    "        else:\n",
    "            last_token = token.value.upper()\n",
    "  \n",
    "        \n",
    "    ## CUANDO TERMINA EL TOKEN, PODRÍA QUEDAR LÓGICA POR FUERA DESPUÉS DEL ;\n",
    "    if (rule_generic_list_total and df_final_columns.empty == False): \n",
    "                \n",
    "        df_final_columns = \\\n",
    "                       updateInDataFrameColumnsRules(df_final_columns, rule_generic_list_total) \n",
    "    \n",
    "    \n",
    "    if (df_final_tables.empty == False or df_final_columns.empty == False):\n",
    "        df_merge_table_column_input = mergeDataframeTablesColumnsQuery(df_final_tables, df_final_columns)\n",
    "    \n",
    "    return df_merge_table_column_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de procesamiento de query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    \"\"\" remove c-style comments.\n",
    "        text: blob of text with comments (can include newlines)\n",
    "        returns: text with comments removed\n",
    "    \"\"\"\n",
    "    pattern = r\"\"\"\n",
    "                            ##  --------- COMMENT ---------\n",
    "           /\\*              ##  Start of /* ... */ comment\n",
    "           [^*]*\\*+         ##  Non-* followed by 1-or-more *'s\n",
    "           (                ##\n",
    "             [^/*][^*]*\\*+  ##\n",
    "           )*               ##  0-or-more things which don't start with /\n",
    "                            ##    but do end with '*'\n",
    "           /                ##  End of /* ... */ comment\n",
    "         |                  ##  -OR-  various things which aren't comments:\n",
    "           (                ## \n",
    "                            ##  ------ \" ... \" STRING ------\n",
    "             \"              ##  Start of \" ... \" string\n",
    "             (              ##\n",
    "               \\\\.          ##  Escaped char\n",
    "             |              ##  -OR-\n",
    "               [^\"\\\\]       ##  Non \"\\ characters\n",
    "             )*             ##\n",
    "             \"              ##  End of \" ... \" string\n",
    "           |                ##  -OR-\n",
    "                            ##\n",
    "                            ##  ------ ' ... ' STRING ------\n",
    "             '              ##  Start of ' ... ' string\n",
    "             (              ##\n",
    "               \\\\.          ##  Escaped char\n",
    "             |              ##  -OR-\n",
    "               [^'\\\\]       ##  Non '\\ characters\n",
    "             )*             ##\n",
    "             '              ##  End of ' ... ' string\n",
    "           |                ##  -OR-\n",
    "                            ##\n",
    "                            ##  ------ ANYTHING ELSE -------\n",
    "             .              ##  Anything other char\n",
    "             [^/\"'\\\\]*      ##  Chars which doesn't start a comment, string\n",
    "           )                ##    or escape\n",
    "    \"\"\"\n",
    "    regex = re.compile(pattern, re.VERBOSE|re.MULTILINE|re.DOTALL)\n",
    "    noncomments = [m.group(2) for m in regex.finditer(text) if m.group(2)]\n",
    "\n",
    "    return \"\".join(noncomments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteInconsistencyQuery(queryString):\n",
    "    '''\n",
    "    Función que elimina caracteres varios de una query\n",
    "    '''    \n",
    "    characters = '[%#${}]'\n",
    "    finalQuery = re.sub(characters, '', str(queryString))\n",
    "    return finalQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones: Insertar en Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dataframe_in_csv(df):\n",
    "    '''\n",
    "    Función que crea un archivo de levantamiento desde un dataframe\n",
    "    '''\n",
    "    \n",
    "    with open('LAC_Levantamiento_CIM.csv', 'a') as f:\n",
    "        df.to_csv(f, sep='|', index=None, header=f.tell()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyDataframeExtractQuery():\n",
    "    '''\n",
    "    Función que retorna un objeto dataframe vacío \n",
    "    para obtener las tablas, campos y reglas de una query\n",
    "    \n",
    "    Formato ['NOMBRE_COMUNICACION','NOMBRE_SEGMENTO','MULTINIVEL',ESQUEMA_INPUT','TABLA_INPUT',\n",
    "             'ALIAS_SUBQUERY','COLUMNA', 'VARIABLE','LOGICA_NEGOCIO','ALIAS_CAMPO']\n",
    "    '''\n",
    "    \n",
    "    columnsDF = ['NOMBRE_COMUNICACION','NOMBRE_SEGMENTO','MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT',\n",
    "                 'ALIAS_SUBQUERY','COLUMNA','VARIABLE', 'LOGICA_NEGOCIO', 'ALIAS_CAMPO']\n",
    "\n",
    "    df = pd.DataFrame(columns = columnsDF) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyDataframeTablesColumnsInputQuery():\n",
    "    '''\n",
    "    Función que retorna un objeto dataframe vacío para obtener los campos y reglas de una query    \n",
    "    Formato ['MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT','ALIAS_SUBQUERY',\n",
    "             'NOMBRE_CAMPO', 'CAMPO_COMPUESTO','LOGICA_NEGOCIO','ALIAS_CAMPO']\n",
    "    '''\n",
    "    \n",
    "    columnsDF = ['MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT','ALIAS_SUBQUERY',\n",
    "                 'NOMBRE_CAMPO', 'CAMPO_COMPUESTO','LOGICA_NEGOCIO','ALIAS_CAMPO']\n",
    "    \n",
    "    df = pd.DataFrame(columns = columnsDF) \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extract_columns_tables_query(communication, segment, queryString):\n",
    "    '''\n",
    "    Función que crea un archivo de levantamiento desde un dataframe\n",
    "    '''\n",
    "    \n",
    "    list_table_input  = []\n",
    "    list_table_output = []\n",
    "    columns = ['NOMBRE_COMUNICACION','NOMBRE_SEGMENTO','MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT',\n",
    "               'ALIAS_SUBQUERY','COLUMNA','VARIABLE','LOGICA_NEGOCIO', 'ALIAS_CAMPO']\n",
    "    \n",
    "    df_final_merge       = emptyDataframeExtractQuery()\n",
    "    df_merge_table_input = emptyDataframeTablesColumnsInputQuery()\n",
    "\n",
    "    \n",
    "    df_merge_table_input = get_query_tables_and_columns(queryString)\n",
    "\n",
    "    df_merge_table_input = df_merge_table_input.rename(columns={\n",
    "                                                    'NOMBRE_CAMPO'   : 'COLUMNA',\n",
    "                                                    'CAMPO_COMPUESTO': 'VARIABLE'})\n",
    "        \n",
    "    df_final_merge = df_final_merge.append(df_merge_table_input, sort=True)   \n",
    "\n",
    "\n",
    "    df_final_merge = df_final_merge.assign(NOMBRE_COMUNICACION = communication, NOMBRE_SEGMENTO = segment)\n",
    "    \n",
    "    # Reordenando los campos del dataframe \n",
    "    df_final_merge = df_final_merge.reindex(columns , axis=1)\n",
    "    df_final_merge = df_final_merge.replace(to_replace='nan.', value='', regex=True)\n",
    "    df_final_merge = df_final_merge.replace(to_replace='nan',  value='', regex=True)\n",
    "    \n",
    "    return df_final_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyDataframeTablesQuery(data):\n",
    "    '''\n",
    "    Función que retorna un objeto dataframe vacío para obtener las tablas de una query\n",
    "    Formato ['MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT','ALIAS_TABLA','ALIAS_SUBQUERY']\n",
    "    '''\n",
    "    \n",
    "    columnsDF = ['MULTINIVEL','ESQUEMA_INPUT','TABLA_INPUT','ALIAS_TABLA', 'ALIAS_SUBQUERY']\n",
    "    \n",
    "    if data is not None:\n",
    "        df = pd.DataFrame(columns = columnsDF) \n",
    "    else:\n",
    "        df = pd.DataFrame(data,columns = columnsDF) \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyDataframeColumnsQuery(data):\n",
    "    '''\n",
    "    Función que retorna un objeto dataframe vacío para obtener los campos y reglas de una query    \n",
    "    Formato ['MULTINIVEL','CAMPOS','LOGICA_NEGOCIO','ALIAS_CAMPO']\n",
    "    '''\n",
    "    \n",
    "    columnsDF = ['MULTINIVEL','CAMPOS','LOGICA_NEGOCIO','ALIAS_CAMPO']\n",
    "    \n",
    "    if data is not None:\n",
    "        df = pd.DataFrame(columns = columnsDF) \n",
    "    else:\n",
    "        df = pd.DataFrame(data,columns = columnsDF) \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertaEnArchivoDF(file, df):\n",
    "    '''\n",
    "    Función que inserta un dataframe a un archivo\n",
    "    '''    \n",
    "    df.to_csv(file, header=True, index=None, sep='|', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query desde TERADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_querys_cim_teradata():\n",
    "    '''\n",
    "    Función que busca en Teradata las querys a procesar según comunicación y segmentación\n",
    "    '''\n",
    "\n",
    "    # Archivo que contiene la query y las comunicaciones que se van a analizar\n",
    "    filename        = 'query_segmentos_CIM_prod.txt'\n",
    "    archivo         = open(filename, encoding=\"utf8\",errors='ignore')\n",
    "    query_segments  = archivo.read()\n",
    "    \n",
    "    with giraffez.BulkExport(query_segments, **td_config) as export:\n",
    "        dataset = export.to_list()\n",
    "        \n",
    "    headers = ['NOMBRE_COMUNICACION','SEGMENTO', 'QUERY_CIM', 'ULTIMA_FECHA']\n",
    "\n",
    "    df = pd.DataFrame(dataset, columns = headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-11 17:41:45.944173\n",
      "ELIMINANDO Y CREANDO TABLAS..\n",
      "\n",
      "INSERTANDO ARCHIVO A LA TABLA EDW_TEMPUSU.LAC_LEVANTAMIENTO_CIM..\n",
      "\n",
      "2020-05-11 17:49:44.127399\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    now = datetime.datetime.now()\n",
    "    print (now)\n",
    "    \n",
    "    '''\n",
    "    Sección donde extraer las reglas, campos, tablas de las querys de las segmentaciones\n",
    "    y exclusiones de ciertas comunicaciones en CIM\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    df = get_querys_cim_teradata()\n",
    "    query_cim_list = df.values.tolist()\n",
    "   \n",
    "    df_extract_querys_cim = emptyDataframeExtractQuery()\n",
    "   \n",
    "    \n",
    "    process_number = 0\n",
    "    for query in query_cim_list:\n",
    "        \n",
    "                        \n",
    "        process_number += 1  \n",
    "\n",
    "        communication = query[0]\n",
    "        segment       = query[1]\n",
    "        queryString   = query[2]\n",
    "\n",
    "        queryString = queryString.replace('\"','')\n",
    "\n",
    "        queryString = deleteInconsistencyQuery(queryString)\n",
    "\n",
    "        queryString = re.sub('\\-\\-.*?\\n|\\/\\*.*?\\*\\/', ' ', queryString)  \n",
    "\n",
    "        queryString = remove_comments(queryString)\n",
    "\n",
    "        #print(process_number)\n",
    "        \n",
    "        '''\n",
    "        if(process_number > 803):\n",
    "            print(process_number)\n",
    "            #print(queryString)\n",
    "        '''\n",
    "        \n",
    "        # Retorna todas las tablas input, campos y reglas\n",
    "        df_internal_querys_cim = get_extract_columns_tables_query(communication, segment, queryString)\n",
    "\n",
    "        if (df_internal_querys_cim.empty == False):\n",
    "            df_extract_querys_cim = df_extract_querys_cim.append(df_internal_querys_cim)\n",
    "\n",
    "\n",
    "    # Inserta todo el analisis de extracción de tablas a un archivo .CSV\n",
    "    insert_dataframe_in_csv(df_extract_querys_cim)  \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Sección donde crea e inserta en la tabla temporal de Teradata la información obtenida\n",
    "    '''\n",
    "    # Elimina y crea las tablas en Teradata\n",
    "    create_and_drop_tables_teradata()\n",
    "    \n",
    "    # Inserta el contenido de los archivos a las tablas en Teradata\n",
    "    insert_files_csv_in_teradata()\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print (now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insertaEnArchivoDF(\"resultados_segmentaciones_querys_cim.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
