{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levantamiento Tablas originales de las Vistas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **PROYECTO : LEVANTAMIENTO TABLAS ORIGINALES QUE ALIMENTAN A LAS VISTAS GESTOR DE CAMPAÑAS TERADATA** <br> \n",
    "**Extracción de tablas originales utilizadas en las Vistas** <br>\n",
    "Los archivos a procesar están en la carpeta ./ArchivosProcesar  <br>\n",
    "Versión:  1.0  <br>\n",
    "Fecha: 01-05-2020  <br>\n",
    "Descripción: Versión Inicial  <br>\n",
    "Desarrollador: Axity | Adriana Jiménez "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os, glob\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "## Libreria que se integra con Teradata\n",
    "import giraffez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones: Insertar en BD Teradata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuracion de conexion\n",
    "td_config = {\n",
    "    \"username\": \"exajibl\",\n",
    "    \"password\": \"acjb0610\",\n",
    "    \"host\": \"dataware.bci.cl\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_drop_tables_teradata():\n",
    "    '''\n",
    "    Función que crea las tablas en Teradata\n",
    "    '''\n",
    "    \n",
    "    print(\"ELIMINANDO Y CREANDO TABLAS..\\n\")\n",
    "    \n",
    "    drop_views_views   = \"DROP TABLE EDW_TEMPUSU.LAC_LISTA_VISTAS_DE_VISTAS\"\n",
    "    drop_views_tables  = \"DROP TABLE EDW_TEMPUSU.LAC_VISTAS_Y_TABLAS_ORIGEN\"\n",
    "\n",
    "    create_views_views = \"\"\"CREATE MULTISET TABLE EDW_TEMPUSU.LAC_LISTA_VISTAS_DE_VISTAS\n",
    "        (\n",
    "          TABLA_OUTPUT_COMPUESTA VARCHAR(200) ,\n",
    "          ESQUEMA_INPUT VARCHAR(50) ,\n",
    "          TABLA_INPUT_COMPUESTA VARCHAR(200)      \n",
    "          ) ;\"\"\"\n",
    "\n",
    "    create_views_tables = \"\"\"CREATE MULTISET TABLE EDW_TEMPUSU.LAC_VISTAS_Y_TABLAS_ORIGEN\n",
    "        (\n",
    "          VISTA_OUTPUT VARCHAR(200) ,\n",
    "          TABLA_INPUT VARCHAR(300)      \n",
    "          ) ;\"\"\"\n",
    "    \n",
    "    with giraffez.Cmd(**td_config) as cmd:\n",
    "        if cmd.exists(\"EDW_TEMPUSU.LAC_LISTA_VISTAS_DE_VISTAS\"):\n",
    "            cmd.execute(drop_views_views)\n",
    "        if cmd.exists(\"EDW_TEMPUSU.LAC_VISTAS_Y_TABLAS_ORIGEN\"):\n",
    "            cmd.execute(drop_views_tables)\n",
    "\n",
    "        cmd.execute(create_views_views)\n",
    "        cmd.execute(create_views_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_files_csv_in_teradata(df):\n",
    "    '''\n",
    "    Función que inserta los dataframes a Teradata\n",
    "    '''\n",
    "    \n",
    "    print(\"INSERTANDO ARCHIVOS A LAS TABLAS..\\n\")\n",
    "\n",
    "    if (df.empty == False): \n",
    "        \n",
    "        with giraffez.BulkLoad(\"EDW_TEMPUSU.LAC_LISTA_VISTAS_DE_VISTAS\", **td_config) as load:\n",
    "            load.cleanup()\n",
    "            load.columns = df.columns.tolist()\n",
    "            for row in df.values.tolist(): \n",
    "                load.put([row[0], row[1], row[2] ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_result_in_teradata(df):\n",
    "    '''\n",
    "    Función que inserta los dataframes a Teradata\n",
    "    '''\n",
    "    \n",
    "    print(\"INSERTANDO INFO. DE TABLAS ORIGENES DE LAS VISTAS EN TERADATA..\\n\")\n",
    "    \n",
    "    if (df.empty == False): \n",
    "        \n",
    "        df['VISTA_OUTPUT']  = df['VISTA_OUTPUT'].astype('str')\n",
    "        df['TABLA_INPUT']   = df['TABLA_INPUT'].astype('str')\n",
    "        \n",
    "        with giraffez.BulkLoad(\"EDW_TEMPUSU.LAC_VISTAS_Y_TABLAS_ORIGEN\", **td_config) as load:\n",
    "            load.cleanup()\n",
    "            load.columns = df.columns.tolist()\n",
    "            for row in df.values.tolist():\n",
    "                load.put([ row[0], row[1] ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_existing_views(views):\n",
    "    '''Buscar en Teradata las vistas extraídas de los archivos, \n",
    "       para ver si existen realmente en base de datos\n",
    "    '''\n",
    "\n",
    "    query_get_real_views = \"\"\"SELECT TRIM(databasename)||'.'||TRIM(tablename) AS NOMBRE_VISTAS\n",
    "                                 FROM dbc.tables \n",
    "                                WHERE tablekind='V' \n",
    "                                  and databasename='ARMVIEWS'\n",
    "                                  and tablename in {} \"\"\".format(views)\n",
    "    \n",
    "    \n",
    "    with giraffez.BulkExport(query_get_real_views, **td_config) as export:\n",
    "        dataset = export.to_list()\n",
    "    \n",
    "    headers = ['NOMBRE_VISTAS']\n",
    "    df = pd.DataFrame(dataset, columns = headers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones: Insertar en Teradata las Vistas creadas por Vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_groupby_views(df_vistas):\n",
    "    \n",
    "    cols_output = ['ESQUEMA_OUTPUT', 'TABLA_OUTPUT'] \n",
    "\n",
    "    cols_input  = ['ESQUEMA_INPUT', 'TABLA_INPUT']\n",
    "\n",
    "    columns = ['TABLA_OUTPUT_COMPUESTA','ESQUEMA_INPUT','TABLA_INPUT_COMPUESTA']\n",
    "    \n",
    "    # Genero un campo compuesto con el formato esquema.tabla \n",
    "    df_vistas['TABLA_OUTPUT_COMPUESTA'] = df_vistas[cols_output].\\\n",
    "                                apply(lambda row: '.'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    df_vistas['TABLA_INPUT_COMPUESTA'] = df_vistas[cols_input].\\\n",
    "                                apply(lambda row: '.'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    df_vistas_groupby_tables = df_vistas[columns].groupby(columns).last().reset_index() \n",
    "    \n",
    "    return df_vistas_groupby_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función que por cada vista, retorna las tablas internas que la creó\n",
    "Ej: Ocurre para los casos que una vista fue creada por otra vista\n",
    "'''\n",
    "def loop_return_tables_in_views(list_tables_views):\n",
    "\n",
    "    list_views = []\n",
    "    list_querys_show_views = []\n",
    "    \n",
    "    list_only_views         = []  # lista que tenga VISTA creada por VISTAS.\n",
    "    list_final_tables_views = []  # Lista que guardará todo el levantamiento de todas las tablas.\n",
    "    \n",
    "    \n",
    "    ## Lista que retorna TABLA_OUTPUT_COMPUESTA|ESQUEMA_INPUT|TABLA_INPUT_COMPUESTA\n",
    "    for list_view in list_tables_views:\n",
    "        \n",
    "        ouput_view        = list_view[0]\n",
    "        schema_input_view = list_view[1]\n",
    "        input_view        = list_view[2]\n",
    "        \n",
    "        ## Aqui filtro todo lo que sea INPUT de Vistas\n",
    "        if (schema_input_view == 'ARMVIEWS'):       \n",
    "            list_only_views.append(list_view)\n",
    "        else:\n",
    "            ## Almaceno las vistas que tienen INPUT de Tablas\n",
    "            list_final_tables_views.append(list_view)\n",
    "            \n",
    "    return list_only_views  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de queries para envío masivo a Airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(_list):\n",
    "    \"\"\"\n",
    "    Makes the list have unique items only and maintains the order\n",
    "    list(set()) won't provide that\n",
    "    :type _list list\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "\n",
    "    for item in _list:\n",
    "        if item not in ret:\n",
    "            ret.append(item)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_for_airflow(list_only_views):\n",
    "    '''Crea un archivo que genera una lista de vistas existentes'''\n",
    "    \n",
    "    airflow_file =open('Resultados/querys_show_qualified_para_airflow.txt','w')\n",
    "\n",
    "    # Hacerle split a las vistas output\n",
    "    list_ = []\n",
    "    for views in list_only_views:\n",
    "        view = views[0].split('.')[1]\n",
    "        list_.append(view)\n",
    "\n",
    "    # Hacer una lista unica VISTA\n",
    "    list_unique_views = unique(list_)\n",
    "\n",
    "    # Convertir la lista en tupla\n",
    "    def convert_to_tuple(list): \n",
    "        return (*list,)\n",
    "\n",
    "    tuple_views = convert_to_tuple(list_unique_views)\n",
    "\n",
    "    # Buscar en Teradata si las vistas existen realmente en la BD\n",
    "    df_unique_views = get_real_existing_views(tuple_views) \n",
    "    unique_views    = df_unique_views.values.tolist()\n",
    "\n",
    "    for view in unique_views:\n",
    "        print(view)\n",
    "        #static_select    = \"SELECT '\"+ view + \"';\"\n",
    "        static_show_view = \"SHOW QUALIFIED SELECT * FROM \"+ view[0]+ \";\"\n",
    "\n",
    "        #airflow_file.write(\"%s\" % static_select +'\\n')\n",
    "        airflow_file.write(\"%s\" % static_show_view +'\\n')\n",
    "\n",
    "    airflow_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_into_dataframe(total_results_list):\n",
    "\n",
    "    headers   = ['VISTA_OUTPUT', 'TABLA_INPUT']\n",
    "    \n",
    "    df_final  = pd.DataFrame(columns = headers)\n",
    "    \n",
    "    for list_views_tables in total_results_list:\n",
    "        view = list_views_tables[0] \n",
    "        lenght_list = len(list_views_tables)\n",
    "    \n",
    "        for i in range(1, lenght_list):\n",
    "            \n",
    "            table = list_views_tables[i]          \n",
    "        \n",
    "            new_df_tables = pd.DataFrame(columns = headers)\n",
    "            \n",
    "            new_df_tables = new_df_tables.append(\n",
    "                [ {'VISTA_OUTPUT' : view, \n",
    "                   'TABLA_INPUT'  : table\n",
    "                  }]) \n",
    "            \n",
    "            df_final = df_final.append(new_df_tables,ignore_index=True,sort=False)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_files(log_airflow):\n",
    "    \n",
    "    ## Lista de sintaxis SQL que debería tomar cada linea del archivo,\n",
    "    ## Obtener solo las SHOW QUALIFIED, CREATE TABLES Y ERRORES.\n",
    "    \n",
    "    show_qualified_str    = 'SHOW QUALIFIED SELECT'\n",
    "    create_ddl_str        = 'CREATE SET TABLE'\n",
    "    failure_message_str   = '*** FAILURE'\n",
    "    \n",
    "    view_and_tables_list  = []\n",
    "    total_results_list    = []\n",
    "    \n",
    "    dml_dll_syntax_query = [ show_qualified_str, create_ddl_str, failure_message_str ]   \n",
    "        \n",
    "    clear_log  = re.sub('[[\\]{}].*[[\\]{}]', ' ', log_airflow)   ## elimina las llaves y corchetes con su contenido\n",
    "    clear_log = clear_log.replace(\" INFO - \",'')                ## elimina los INFO mensajes\n",
    "    clear_log = clear_log.replace(\"+\",'')                       ## reemplaza otros caracteres\n",
    "    clear_log = re.sub('\\-\\-.*?\\n|\\/\\*.*?\\*\\/', ' ', clear_log) ## elimina los comentarios  \n",
    "    clear_log = clear_log.strip()\n",
    "        \n",
    "    lines = clear_log.splitlines();\n",
    "            \n",
    "    for line in lines: \n",
    "        # elimina espacios a comienzo de la linea y lo edita a mayuscula\n",
    "        line = line.strip().upper()                \n",
    "        \n",
    "        # comienza agregando las querys que interesan\n",
    "        if line.startswith(tuple(dml_dll_syntax_query)): \n",
    "            \n",
    "            if (line.startswith(show_qualified_str)):  ## comienza con SHOW QUALIFIED\n",
    "                \n",
    "                if (len(view_and_tables_list) > 0):\n",
    "                    total_results_list.append(view_and_tables_list)\n",
    "                    view_and_tables_list = []\n",
    "                \n",
    "                ## Obtiene ESQUEMA.VISTA directamente de la query\n",
    "                ## Ej: SHOW QUALIFIED SELECT * FROM ARMVIEWS.VISTA_A;\n",
    "                view = re.findall(r'[\\w\\.-]+\\.[\\w\\.-]+', line)[0] \n",
    "                view_and_tables_list.append(view)\n",
    "                \n",
    "            elif(line.startswith(create_ddl_str)):    ## comienza con CREATE TABLE                \n",
    "                \n",
    "                ## Obtiene ESQUEMA.TABLA directamente de la query\n",
    "                ## Ej: CREATE SET TABLE ARMINP.TABLA_1 ,FALLBACK ,\n",
    "                table = re.findall(r'[\\w\\.-]+\\.[\\w\\.-]+', line)[0]\n",
    "                view_and_tables_list.append(table)              \n",
    "                  \n",
    "            elif(line.startswith(failure_message_str)):  ## comienza con Failure\n",
    "                view_and_tables_list.append(line)\n",
    "    \n",
    "    \n",
    "    if (len(view_and_tables_list) > 0):\n",
    "        total_results_list.append(view_and_tables_list)\n",
    "                \n",
    "    return total_results_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_scandir_files(path):\n",
    "    '''\n",
    "    Función que escanea los directorios y subdirectorios,\n",
    "    obteniendo como resultado una lista de archivo con,\n",
    "    formato: ./Directorio/Subdirectorio/archivo\n",
    "    '''\n",
    "\n",
    "    file_list = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if(file.endswith(\".log\")):\n",
    "                file_list.append(os.path.join(root,file))\n",
    "                \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_step():\n",
    "\n",
    "    df_vistas                = pd.read_csv(\"LAC_Levantamiento_Vistas.csv\",  sep='|') \n",
    "    df_vistas_groupby_tables = return_groupby_views(df_vistas)\n",
    "    list_tables_views        = df_vistas_groupby_tables.values.tolist()\n",
    "    list_only_views          = loop_return_tables_in_views(list_tables_views)\n",
    "\n",
    "    headers      = ['TABLA_OUTPUT_COMPUESTA','ESQUEMA_INPUT','TABLA_INPUT_COMPUESTA']\n",
    "    df_only_view = pd.DataFrame(list_only_views, columns = headers)\n",
    "    \n",
    "    create_and_drop_tables_teradata()\n",
    "    \n",
    "    insert_files_csv_in_teradata(df_only_view)\n",
    "    \n",
    "    return list_only_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_from_log_airflow():\n",
    "\n",
    "    dir_logs = 'Logs_Airflow/'\n",
    "    log_files = fast_scandir_files(dir_logs)\n",
    "    log_files.sort()\n",
    "\n",
    "    headers   = ['VISTA_OUTPUT', 'TABLA_INPUT']\n",
    "    df_final_all_logs  = pd.DataFrame(columns = headers)\n",
    "\n",
    "    for log in log_files:\n",
    "        print(log)\n",
    "        \n",
    "        filename        = log\n",
    "        archivo         = open(filename, encoding=\"utf8\",errors='ignore')\n",
    "        log_airflow     = archivo.read()\n",
    "\n",
    "        total_results_list      = processing_files(log_airflow)\n",
    "        df_final_results_by_log = convert_list_into_dataframe(total_results_list)\n",
    "\n",
    "        df_final_all_logs = df_final_all_logs.append(df_final_results_by_log, ignore_index=True, sort=False)\n",
    "        \n",
    "        \n",
    "    df_final_all_logs.to_csv(\"Resultados/resultados_logs_airflow.csv\", header=True, index=None, sep='|', mode='w') \n",
    "    \n",
    "    # Elimina y crea tablas en teradata\n",
    "    create_and_drop_tables_teradata()\n",
    "    \n",
    "    # Inserta el dataframe a Teradata\n",
    "    insert_result_in_teradata(df_final_all_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-11 19:04:38.096386\n",
      "ELIMINANDO Y CREANDO TABLAS..\n",
      "\n",
      "INSERTANDO ARCHIVOS A LAS TABLAS..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    print (now)\n",
    "    \n",
    "    ###### PASO 1)\n",
    "    '''\n",
    "        Sección que extrae del archivo de vistas, las vistas que estan creadas por otras vistas\n",
    "        y retorna una lista unica de las mismas. Además inserta la lista en teradata para su \n",
    "        posterior consulta.\n",
    "        \n",
    "        Condición: Debe existir el archivo LAC_Levantamiento_Vistas.csv generado en el proceso\n",
    "        del notebook 03_LAC_Logicas_Negocio_Bteq_SP_Vistas.ipynb\n",
    "    '''       \n",
    "    list_only_views = first_step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' ------------------------------------------------------------------- '''\n",
    "    \n",
    "    ###### PASO 2)\n",
    "    '''\n",
    "        Sección que crea un archivo con la lista unica de vistas y una serie de queries que contiene\n",
    "        multiples SHOW QUALIFIED para analizarlas masivamente desde Airflow (proceso externo a este notebook)\n",
    "        \n",
    "        Solo se genera ese archivo llamado: Resultados/querys_show_qualified_para_airflow.txt\n",
    "    '''    \n",
    "    #create_file_for_airflow(list_only_views)\n",
    "\n",
    "    \n",
    "    ''' ------------------------------------------------------------------- '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###### PASO 3)\n",
    "    '''\n",
    "        Sección que lee el Log que devuelve Airflow como respuesta a las tablas originales de \n",
    "        las vistas que se les realizó SHOW QUALIFIED.\n",
    "        \n",
    "        Condición: Insertar en la carpeta Logs_Airflow/ el resultado de logs que arrojó Airflow\n",
    "        como respuesta al paso 2)\n",
    "    '''        \n",
    "    #extract_tables_from_log_airflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
